Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:21<00:21, 21.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:27<00:00, 12.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:27<00:00, 13.50s/it]
WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.0622
torch.Size([1, 999])
Data error at batch 0: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 41.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 999])
Data error at batch 1: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 69.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1029])
Data error at batch 2: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 191.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1029])
Data error at batch 3: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 175.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1033])
Data error at batch 4: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 164.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1033])
Data error at batch 5: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 148.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 998])
Data error at batch 6: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 120.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 998])
Data error at batch 7: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 120.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1392])
Data error at batch 8: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 61.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1392])
Data error at batch 9: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 45.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1373])
Data error at batch 10: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 79.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1373])
Data error at batch 11: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 79.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1427])
Data error at batch 12: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 192.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1427])
Data error at batch 13: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 161.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1365])
Data error at batch 14: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 93.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1365])
Data error at batch 15: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 93.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1355])
Data error at batch 16: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 97.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1355])
Data error at batch 17: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 97.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1337])
Data error at batch 18: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 114.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1337])
Data error at batch 19: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 114.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1401])
Data error at batch 20: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1401])
Data error at batch 21: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1354])
Data error at batch 22: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 96.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1354])
Data error at batch 23: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 96.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 925])
Data error at batch 24: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 925])
Data error at batch 25: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 935])
Data error at batch 26: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 935])
Data error at batch 27: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 960])
Data error at batch 28: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 90.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 960])
Data error at batch 29: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 90.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 923])
Data error at batch 30: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 98.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 923])
Data error at batch 31: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 98.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1739])
Data error at batch 32: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1739])
Data error at batch 33: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1734])
Data error at batch 34: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1734])
Data error at batch 35: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1777])
Data error at batch 36: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1777])
Data error at batch 37: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1731])
Data error at batch 38: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1731])
Data error at batch 39: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1342])
Data error at batch 40: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 247.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1342])
Data error at batch 41: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 247.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1365])
Data error at batch 42: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 239.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1365])
Data error at batch 43: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 239.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1366])
Data error at batch 44: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 236.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1366])
Data error at batch 45: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 236.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1335])
Data error at batch 46: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 252.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1335])
Data error at batch 47: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 252.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1553])
Data error at batch 48: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 156.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1553])
Data error at batch 49: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 156.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1541])
Data error at batch 50: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 162.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1541])
Data error at batch 51: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 162.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1566])
Data error at batch 52: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 151.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1566])
Data error at batch 53: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 151.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1526])
Data error at batch 54: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 166.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1526])
Data error at batch 55: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 166.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 942])
Data error at batch 56: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 107.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 942])
Data error at batch 57: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 107.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 933])
Data error at batch 58: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 117.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 933])
Data error at batch 59: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 117.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 954])
Data error at batch 60: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 954])
Data error at batch 61: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 931])
Data error at batch 62: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 119.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 931])
Data error at batch 63: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 119.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1034])
Data error at batch 64: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 146.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1034])
Data error at batch 65: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 146.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1077])
Data error at batch 66: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 140.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1077])
Data error at batch 67: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 140.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1073])
Data error at batch 68: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1073])
Data error at batch 69: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1040])
Data error at batch 70: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 165.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1040])
Data error at batch 71: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 165.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 840])
Data error at batch 72: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 89.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 840])
Data error at batch 73: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 89.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 841])
Data error at batch 74: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 841])
Data error at batch 75: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 896])
Data error at batch 76: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 896])
Data error at batch 77: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 852])
Data error at batch 78: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 852])
Data error at batch 79: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1467])
Data error at batch 80: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 192.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1467])
Data error at batch 81: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 192.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1476])
Data error at batch 82: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1476])
Data error at batch 83: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1519])
Data error at batch 84: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 168.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1519])
Data error at batch 85: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 168.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1464])
Data error at batch 86: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 193.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1464])
Data error at batch 87: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 193.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1398])
Data error at batch 88: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 219.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1398])
Data error at batch 89: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 219.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1417])
Data error at batch 90: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 213.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1417])
Data error at batch 91: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 213.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1475])
Data error at batch 92: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1475])
Data error at batch 93: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1399])
Data error at batch 94: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 219.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1399])
Data error at batch 95: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 219.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 774])
Data error at batch 96: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 774])
Data error at batch 97: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 772])
Data error at batch 98: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 108.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 772])
Data error at batch 99: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 108.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 796])
Data error at batch 100: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 796])
Data error at batch 101: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 755])
Data error at batch 102: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 755])
Data error at batch 103: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 684])
Data error at batch 104: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 684])
Data error at batch 105: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 709])
Data error at batch 106: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 42.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 709])
Data error at batch 107: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 42.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 729])
Data error at batch 108: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 729])
Data error at batch 109: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 687])
Data error at batch 110: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 50.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 687])
Data error at batch 111: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 50.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 675])
Data error at batch 112: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 675])
Data error at batch 113: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 664])
Data error at batch 114: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 664])
Data error at batch 115: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 664])
Data error at batch 116: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 664])
Data error at batch 117: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 669])
Data error at batch 118: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 669])
Data error at batch 119: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1371])
Data error at batch 120: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 234.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1371])
Data error at batch 121: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 234.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1381])
Data error at batch 122: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 230.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1381])
Data error at batch 123: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 230.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1376])
Data error at batch 124: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 232.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1376])
Data error at batch 125: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 232.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1349])
Data error at batch 126: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 246.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1349])
Data error at batch 127: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 246.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 729])
Data error at batch 128: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 729])
Data error at batch 129: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 741])
Data error at batch 130: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 62.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 741])
Data error at batch 131: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 62.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 770])
Data error at batch 132: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 770])
Data error at batch 133: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 729])
Data error at batch 134: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 729])
Data error at batch 135: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 952])
Data error at batch 136: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 99.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 952])
Data error at batch 137: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 99.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 974])
Data error at batch 138: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 186.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 974])
Data error at batch 139: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 186.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 985])
Data error at batch 140: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 179.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 985])
Data error at batch 141: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 179.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 948])
Data error at batch 142: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 101.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 948])
Data error at batch 143: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 101.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1296])
Data error at batch 144: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 181.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1296])
Data error at batch 145: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 181.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1301])
Data error at batch 146: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 181.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1301])
Data error at batch 147: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 181.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1326])
Data error at batch 148: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 197.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1326])
Data error at batch 149: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 197.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1284])
Data error at batch 150: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 191.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1284])
Data error at batch 151: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 191.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 702])
Data error at batch 152: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 702])
Data error at batch 153: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 706])
Data error at batch 154: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 706])
Data error at batch 155: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 722])
Data error at batch 156: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 722])
Data error at batch 157: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 702])
Data error at batch 158: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 702])
Data error at batch 159: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1510])
Data error at batch 160: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1510])
Data error at batch 161: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1499])
Data error at batch 162: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 175.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1499])
Data error at batch 163: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 175.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1505])
Data error at batch 164: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 173.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1505])
Data error at batch 165: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 173.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1495])
Data error at batch 166: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 176.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1495])
Data error at batch 167: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 176.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 702])
Data error at batch 168: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 702])
Data error at batch 169: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 723])
Data error at batch 170: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 723])
Data error at batch 171: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 735])
Data error at batch 172: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 735])
Data error at batch 173: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 708])
Data error at batch 174: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 708])
Data error at batch 175: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1371])
Data error at batch 176: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 234.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1371])
Data error at batch 177: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 234.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1416])
Data error at batch 178: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 213.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1416])
Data error at batch 179: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 213.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1379])
Data error at batch 180: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 231.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1379])
Data error at batch 181: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 231.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1354])
Data error at batch 182: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 242.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1354])
Data error at batch 183: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 242.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 594])
Data error at batch 184: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 40.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 594])
Data error at batch 185: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 40.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 597])
Data error at batch 186: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 36.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 597])
Data error at batch 187: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 36.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 597])
Data error at batch 188: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 36.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 597])
Data error at batch 189: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 36.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 582])
Data error at batch 190: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 582])
Data error at batch 191: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2302])
Data error at batch 192: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 101.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2302])
Data error at batch 193: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 101.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2314])
Data error at batch 194: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2314])
Data error at batch 195: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2311])
Data error at batch 196: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2311])
Data error at batch 197: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2259])
Data error at batch 198: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 118.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2259])
Data error at batch 199: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 118.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1308])
Data error at batch 200: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 177.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1308])
Data error at batch 201: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 177.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1346])
Data error at batch 202: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 155.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1346])
Data error at batch 203: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 155.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1319])
Data error at batch 204: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 174.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1319])
Data error at batch 205: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 174.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1309])
Data error at batch 206: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 178.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1309])
Data error at batch 207: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 178.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 684])
Data error at batch 208: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 684])
Data error at batch 209: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 689])
Data error at batch 210: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 689])
Data error at batch 211: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 729])
Data error at batch 212: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 729])
Data error at batch 213: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 686])
Data error at batch 214: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 686])
Data error at batch 215: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 806])
Data error at batch 216: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 806])
Data error at batch 217: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 806])
Data error at batch 218: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 806])
Data error at batch 219: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 847])
Data error at batch 220: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 41.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 847])
Data error at batch 221: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 41.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 799])
Data error at batch 222: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 799])
Data error at batch 223: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1727])
Data error at batch 224: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 190.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1727])
Data error at batch 225: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 190.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1748])
Data error at batch 226: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 180.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1748])
Data error at batch 227: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 180.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1778])
Data error at batch 228: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 168.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1778])
Data error at batch 229: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 168.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1766])
Data error at batch 230: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1766])
Data error at batch 231: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 801])
Data error at batch 232: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 801])
Data error at batch 233: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 830])
Data error at batch 234: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 830])
Data error at batch 235: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 846])
Data error at batch 236: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 42.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 846])
Data error at batch 237: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 42.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 821])
Data error at batch 238: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 821])
Data error at batch 239: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2497])
Data error at batch 240: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 123.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2497])
Data error at batch 241: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 123.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2508])
Data error at batch 242: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 121.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2508])
Data error at batch 243: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 121.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2536])
Data error at batch 244: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 113.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2536])
Data error at batch 245: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 113.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2478])
Data error at batch 246: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 133.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2478])
Data error at batch 247: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 133.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1191])
Data error at batch 248: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 92.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1191])
Data error at batch 249: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 92.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1194])
Data error at batch 250: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1194])
Data error at batch 251: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1214])
Data error at batch 252: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 100.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1214])
Data error at batch 253: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 100.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1163])
Data error at batch 254: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 105.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1163])
Data error at batch 255: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 105.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1965])
Data error at batch 256: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 35.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 225.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1965])
Data error at batch 257: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 41.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 177.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2005])
Data error at batch 258: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 181.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2005])
Data error at batch 259: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 181.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2023])
Data error at batch 260: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 175.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2023])
Data error at batch 261: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 175.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2003])
Data error at batch 262: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 182.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2003])
Data error at batch 263: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 182.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1817])
Data error at batch 264: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 202.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1817])
Data error at batch 265: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 202.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1866])
Data error at batch 266: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 184.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1866])
Data error at batch 267: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 184.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1848])
Data error at batch 268: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 192.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1848])
Data error at batch 269: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 192.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1832])
Data error at batch 270: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 197.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1832])
Data error at batch 271: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 197.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1106])
Data error at batch 272: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 100.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1106])
Data error at batch 273: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 101.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1084])
Data error at batch 274: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1084])
Data error at batch 275: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1132])
Data error at batch 276: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 81.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1132])
Data error at batch 277: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 81.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1076])
Data error at batch 278: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1076])
Data error at batch 279: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1044])
Data error at batch 280: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 105.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1044])
Data error at batch 281: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 105.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1073])
Data error at batch 282: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 83.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1073])
Data error at batch 283: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 83.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1096])
Data error at batch 284: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1096])
Data error at batch 285: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1045])
Data error at batch 286: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 105.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1045])
Data error at batch 287: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 105.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1333])
Data error at batch 288: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 76.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1333])
Data error at batch 289: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 76.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1321])
Data error at batch 290: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 81.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1321])
Data error at batch 291: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 81.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1365])
Data error at batch 292: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 70.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1365])
Data error at batch 293: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 69.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1324])
Data error at batch 294: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 102.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1324])
Data error at batch 295: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 102.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1323])
Data error at batch 296: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 105.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1323])
Data error at batch 297: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 105.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1333])
Data error at batch 298: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 99.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1333])
Data error at batch 299: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 99.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1342])
Data error at batch 300: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 92.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1342])
Data error at batch 301: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 92.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1298])
Data error at batch 302: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 116.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1298])
Data error at batch 303: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 116.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1165])
Data error at batch 304: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 167.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1165])
Data error at batch 305: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 167.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1141])
Data error at batch 306: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 185.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1141])
Data error at batch 307: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 185.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1180])
Data error at batch 308: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 160.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1180])
Data error at batch 309: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 160.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1146])
Data error at batch 310: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 183.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1146])
Data error at batch 311: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 183.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1135])
Data error at batch 312: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 189.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1135])
Data error at batch 313: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 189.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1154])
Data error at batch 314: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 178.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1154])
Data error at batch 315: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 178.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1162])
Data error at batch 316: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 174.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1162])
Data error at batch 317: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 174.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1107])
Data error at batch 318: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 203.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1107])
Data error at batch 319: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 203.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1714])
Data error at batch 320: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 85.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1714])
Data error at batch 321: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 85.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1728])
Data error at batch 322: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1728])
Data error at batch 323: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1725])
Data error at batch 324: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 68.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1725])
Data error at batch 325: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 68.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1699])
Data error at batch 326: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 79.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1699])
Data error at batch 327: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 79.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1849])
Data error at batch 328: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 113.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1849])
Data error at batch 329: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 115.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1887])
Data error at batch 330: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 72.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1887])
Data error at batch 331: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 73.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1896])
Data error at batch 332: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 50.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1896])
Data error at batch 333: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 80.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1850])
Data error at batch 334: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 103.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1850])
Data error at batch 335: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 103.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 914])
Data error at batch 336: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 60.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 914])
Data error at batch 337: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 60.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 886])
Data error at batch 338: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 886])
Data error at batch 339: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 96.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 937])
Data error at batch 340: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 937])
Data error at batch 341: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 890])
Data error at batch 342: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 890])
Data error at batch 343: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1326])
Data error at batch 344: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 198.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1326])
Data error at batch 345: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 198.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1352])
Data error at batch 346: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 185.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1352])
Data error at batch 347: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 185.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1379])
Data error at batch 348: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1379])
Data error at batch 349: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1312])
Data error at batch 350: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 204.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1312])
Data error at batch 351: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 204.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 934])
Data error at batch 352: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 934])
Data error at batch 353: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 933])
Data error at batch 354: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 933])
Data error at batch 355: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 977])
Data error at batch 356: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 183.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 977])
Data error at batch 357: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 183.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 934])
Data error at batch 358: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 934])
Data error at batch 359: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1665])
Data error at batch 360: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 145.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1665])
Data error at batch 361: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 146.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1678])
Data error at batch 362: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 141.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1678])
Data error at batch 363: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 141.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1712])
Data error at batch 364: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 155.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1712])
Data error at batch 365: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 155.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1667])
Data error at batch 366: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 145.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1667])
Data error at batch 367: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 145.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1325])
Data error at batch 368: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 185.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1325])
Data error at batch 369: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 185.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1312])
Data error at batch 370: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 189.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1312])
Data error at batch 371: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 189.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1346])
Data error at batch 372: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 173.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1346])
Data error at batch 373: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 173.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1308])
Data error at batch 374: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 191.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1308])
Data error at batch 375: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 191.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1269])
Data error at batch 376: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 97.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1269])
Data error at batch 377: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 97.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1269])
Data error at batch 378: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 97.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1269])
Data error at batch 379: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 97.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1291])
Data error at batch 380: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 201.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1291])
Data error at batch 381: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 201.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1262])
Data error at batch 382: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1262])
Data error at batch 383: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 954])
Data error at batch 384: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 84.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 954])
Data error at batch 385: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 84.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 975])
Data error at batch 386: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 122.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 975])
Data error at batch 387: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 122.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 990])
Data error at batch 388: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 178.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 990])
Data error at batch 389: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 178.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 959])
Data error at batch 390: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 81.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 959])
Data error at batch 391: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 81.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1444])
Data error at batch 392: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 87.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1444])
Data error at batch 393: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 87.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1470])
Data error at batch 394: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 74.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1470])
Data error at batch 395: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 74.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1496])
Data error at batch 396: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 46.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1496])
Data error at batch 397: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 46.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1440])
Data error at batch 398: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 89.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1440])
Data error at batch 399: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 89.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1519])
Data error at batch 400: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 44.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1519])
Data error at batch 401: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 44.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1539])
Data error at batch 402: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 140.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1539])
Data error at batch 403: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 140.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1570])
Data error at batch 404: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 127.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1570])
Data error at batch 405: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 127.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1524])
Data error at batch 406: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 112.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1524])
Data error at batch 407: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 112.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1246])
Data error at batch 408: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 212.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1246])
Data error at batch 409: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 212.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1258])
Data error at batch 410: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 207.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1258])
Data error at batch 411: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 207.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1312])
Data error at batch 412: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 167.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1312])
Data error at batch 413: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 167.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1271])
Data error at batch 414: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 191.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1271])
Data error at batch 415: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 191.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1196])
Data error at batch 416: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 180.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1196])
Data error at batch 417: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 180.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1183])
Data error at batch 418: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 233.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1183])
Data error at batch 419: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 233.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1229])
Data error at batch 420: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 169.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1229])
Data error at batch 421: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 169.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1201])
Data error at batch 422: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 180.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1201])
Data error at batch 423: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 180.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1220])
Data error at batch 424: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 171.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1220])
Data error at batch 425: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 171.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1249])
Data error at batch 426: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 200.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1249])
Data error at batch 427: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 200.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1266])
Data error at batch 428: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 191.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1266])
Data error at batch 429: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 191.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1205])
Data error at batch 430: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 178.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1205])
Data error at batch 431: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 178.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1110])
Data error at batch 432: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 230.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1110])
Data error at batch 433: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 230.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1131])
Data error at batch 434: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.71 GiB is allocated by PyTorch, and 260.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1131])
Data error at batch 435: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.71 GiB is allocated by PyTorch, and 260.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1126])
Data error at batch 436: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.71 GiB is allocated by PyTorch, and 262.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1126])
Data error at batch 437: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.71 GiB is allocated by PyTorch, and 262.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1098])
Data error at batch 438: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 202.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1098])
Data error at batch 439: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 202.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1771])
Data error at batch 440: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 56.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1771])
Data error at batch 441: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 60.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1801])
Data error at batch 442: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 139.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1801])
Data error at batch 443: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 117.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1836])
Data error at batch 444: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 46.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1836])
Data error at batch 445: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 82.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1813])
Data error at batch 446: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1813])
Data error at batch 447: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1511])
Data error at batch 448: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 158.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1511])
Data error at batch 449: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 158.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1532])
Data error at batch 450: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 151.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1532])
Data error at batch 451: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 151.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1560])
Data error at batch 452: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 143.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1560])
Data error at batch 453: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 143.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1510])
Data error at batch 454: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 161.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1510])
Data error at batch 455: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 161.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1599])
Data error at batch 456: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 125.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1599])
Data error at batch 457: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 125.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1599])
Data error at batch 458: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 125.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1599])
Data error at batch 459: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 125.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1613])
Data error at batch 460: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 176.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1613])
Data error at batch 461: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 176.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1587])
Data error at batch 462: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 129.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1587])
Data error at batch 463: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 129.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1509])
Data error at batch 464: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 161.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1509])
Data error at batch 465: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 161.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1516])
Data error at batch 466: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 159.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1516])
Data error at batch 467: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 159.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1531])
Data error at batch 468: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 154.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1531])
Data error at batch 469: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 154.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1501])
Data error at batch 470: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 164.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1501])
Data error at batch 471: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 164.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 985])
Data error at batch 472: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 168.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 985])
Data error at batch 473: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 168.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1032])
Data error at batch 474: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 137.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1032])
Data error at batch 475: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 137.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1030])
Data error at batch 476: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 138.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1030])
Data error at batch 477: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 138.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 990])
Data error at batch 478: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 99.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 990])
Data error at batch 479: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 99.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1373])
Data error at batch 480: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 193.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1373])
Data error at batch 481: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 193.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1396])
Data error at batch 482: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 211.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1396])
Data error at batch 483: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 211.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1393])
Data error at batch 484: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 212.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1393])
Data error at batch 485: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 212.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1388])
Data error at batch 486: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 185.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1388])
Data error at batch 487: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 185.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1443])
Data error at batch 488: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 192.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1443])
Data error at batch 489: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 192.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1427])
Data error at batch 490: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 198.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1427])
Data error at batch 491: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 198.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1446])
Data error at batch 492: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 191.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1446])
Data error at batch 493: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 191.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1419])
Data error at batch 494: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 202.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1419])
Data error at batch 495: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 202.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2202])
Data error at batch 496: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 134.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2202])
Data error at batch 497: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 134.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2218])
Data error at batch 498: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2218])
Data error at batch 499: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2255])
Data error at batch 500: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 35.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 84.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2255])
Data error at batch 501: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 35.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 133.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2195])
Data error at batch 502: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 35.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 157.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2195])
Data error at batch 503: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 35.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 157.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2086])
Data error at batch 504: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 35.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 190.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2086])
Data error at batch 505: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 35.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 190.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2132])
Data error at batch 506: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 35.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 176.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2132])
Data error at batch 507: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 35.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 176.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2152])
Data error at batch 508: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 35.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 170.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2152])
Data error at batch 509: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 35.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 170.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2102])
Data error at batch 510: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 35.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 185.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2102])
Data error at batch 511: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 35.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 185.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 638])
Data error at batch 512: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 25.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 638])
Data error at batch 513: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 37.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 659])
Data error at batch 514: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 659])
Data error at batch 515: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 669])
Data error at batch 516: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 61.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 669])
Data error at batch 517: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 61.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 644])
Data error at batch 518: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 43.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 644])
Data error at batch 519: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 43.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 860])
Data error at batch 520: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 860])
Data error at batch 521: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 890])
Data error at batch 522: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 63.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 890])
Data error at batch 523: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 63.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 918])
Data error at batch 524: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 75.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 918])
Data error at batch 525: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 75.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 857])
Data error at batch 526: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 857])
Data error at batch 527: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1042])
Data error at batch 528: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 145.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1042])
Data error at batch 529: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 145.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1055])
Data error at batch 530: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 137.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1055])
Data error at batch 531: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 137.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1066])
Data error at batch 532: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 125.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1066])
Data error at batch 533: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 125.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1030])
Data error at batch 534: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 115.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1030])
Data error at batch 535: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 115.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1264])
Data error at batch 536: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 95.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1264])
Data error at batch 537: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 95.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1254])
Data error at batch 538: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 100.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1254])
Data error at batch 539: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 100.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1297])
Data error at batch 540: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1297])
Data error at batch 541: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 104.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1254])
Data error at batch 542: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 133.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1254])
Data error at batch 543: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 133.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1277])
Data error at batch 544: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 122.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1277])
Data error at batch 545: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 122.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1295])
Data error at batch 546: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 105.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1295])
Data error at batch 547: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 105.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1305])
Data error at batch 548: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 101.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1305])
Data error at batch 549: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 101.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1272])
Data error at batch 550: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 123.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1272])
Data error at batch 551: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 123.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 593])
Data error at batch 552: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 593])
Data error at batch 553: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 642])
Data error at batch 554: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 642])
Data error at batch 555: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 650])
Data error at batch 556: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 650])
Data error at batch 557: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 593])
Data error at batch 558: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 593])
Data error at batch 559: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 659])
Data error at batch 560: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 70.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 659])
Data error at batch 561: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 70.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 654])
Data error at batch 562: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 654])
Data error at batch 563: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 692])
Data error at batch 564: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 692])
Data error at batch 565: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 654])
Data error at batch 566: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 654])
Data error at batch 567: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1243])
Data error at batch 568: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 73.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1243])
Data error at batch 569: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 63.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1239])
Data error at batch 570: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 64.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1239])
Data error at batch 571: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 64.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1256])
Data error at batch 572: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 58.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1256])
Data error at batch 573: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 58.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1224])
Data error at batch 574: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 66.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1224])
Data error at batch 575: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 66.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2010])
Data error at batch 576: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 138.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2010])
Data error at batch 577: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2027])
Data error at batch 578: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2027])
Data error at batch 579: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2079])
Data error at batch 580: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 176.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2079])
Data error at batch 581: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 37.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 144.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2026])
Data error at batch 582: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 37.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 119.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2026])
Data error at batch 583: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 37.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 119.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 629])
Data error at batch 584: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 35.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 629])
Data error at batch 585: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 48.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 662])
Data error at batch 586: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 42.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 662])
Data error at batch 587: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 42.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 662])
Data error at batch 588: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 42.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 662])
Data error at batch 589: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 42.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 642])
Data error at batch 590: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 32.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 642])
Data error at batch 591: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 32.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 682])
Data error at batch 592: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 682])
Data error at batch 593: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 692])
Data error at batch 594: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 692])
Data error at batch 595: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 702])
Data error at batch 596: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 702])
Data error at batch 597: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 679])
Data error at batch 598: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 679])
Data error at batch 599: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1487])
Data error at batch 600: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 241.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1487])
Data error at batch 601: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 218.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1504])
Data error at batch 602: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 209.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1504])
Data error at batch 603: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 209.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1501])
Data error at batch 604: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 210.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1501])
Data error at batch 605: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 210.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1491])
Data error at batch 606: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 216.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1491])
Data error at batch 607: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 216.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 792])
Data error at batch 608: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 61.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 792])
Data error at batch 609: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 829])
Data error at batch 610: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 829])
Data error at batch 611: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 828])
Data error at batch 612: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 828])
Data error at batch 613: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 820])
Data error at batch 614: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 820])
Data error at batch 615: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1248])
Data error at batch 616: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 146.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1248])
Data error at batch 617: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 146.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1258])
Data error at batch 618: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 141.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1258])
Data error at batch 619: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 141.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1280])
Data error at batch 620: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 150.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1280])
Data error at batch 621: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 150.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1235])
Data error at batch 622: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 155.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1235])
Data error at batch 623: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 155.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 774])
Data error at batch 624: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 63.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 774])
Data error at batch 625: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 63.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 793])
Data error at batch 626: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 61.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 793])
Data error at batch 627: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 61.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 799])
Data error at batch 628: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 799])
Data error at batch 629: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 770])
Data error at batch 630: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 770])
Data error at batch 631: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 688])
Data error at batch 632: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 688])
Data error at batch 633: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 709])
Data error at batch 634: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 709])
Data error at batch 635: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 709])
Data error at batch 636: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 709])
Data error at batch 637: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 664])
Data error at batch 638: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 62.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 664])
Data error at batch 639: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 62.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1735])
Data error at batch 640: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 151.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1735])
Data error at batch 641: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 179.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1729])
Data error at batch 642: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 181.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1729])
Data error at batch 643: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 181.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1788])
Data error at batch 644: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 159.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1788])
Data error at batch 645: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 159.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1723])
Data error at batch 646: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 182.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1723])
Data error at batch 647: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 182.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1111])
Data error at batch 648: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 129.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1111])
Data error at batch 649: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 129.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1141])
Data error at batch 650: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 109.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1141])
Data error at batch 651: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 109.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1127])
Data error at batch 652: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 121.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1127])
Data error at batch 653: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 121.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1108])
Data error at batch 654: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 131.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1108])
Data error at batch 655: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 131.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1345])
Data error at batch 656: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 150.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1345])
Data error at batch 657: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 150.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1368])
Data error at batch 658: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 168.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1368])
Data error at batch 659: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 168.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1351])
Data error at batch 660: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 148.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1351])
Data error at batch 661: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 148.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1348])
Data error at batch 662: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 147.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1348])
Data error at batch 663: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 147.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1289])
Data error at batch 664: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 181.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1289])
Data error at batch 665: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 181.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1304])
Data error at batch 666: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 171.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1304])
Data error at batch 667: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 171.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1331])
Data error at batch 668: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 155.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1331])
Data error at batch 669: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 155.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1297])
Data error at batch 670: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 177.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1297])
Data error at batch 671: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 177.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 586])
Data error at batch 672: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 36.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 586])
Data error at batch 673: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 26.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 622])
Data error at batch 674: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 622])
Data error at batch 675: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 623])
Data error at batch 676: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 623])
Data error at batch 677: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 584])
Data error at batch 678: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 28.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 584])
Data error at batch 679: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 28.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1391])
Data error at batch 680: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 47.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1391])
Data error at batch 681: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 69.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1397])
Data error at batch 682: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 69.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1397])
Data error at batch 683: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 69.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1433])
Data error at batch 684: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 134.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1433])
Data error at batch 685: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 134.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1388])
Data error at batch 686: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 123.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1388])
Data error at batch 687: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 123.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1540])
Data error at batch 688: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 131.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1540])
Data error at batch 689: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 131.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1533])
Data error at batch 690: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 100.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1533])
Data error at batch 691: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 100.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1575])
Data error at batch 692: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1575])
Data error at batch 693: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1517])
Data error at batch 694: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 107.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1517])
Data error at batch 695: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 107.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1055])
Data error at batch 696: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 157.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1055])
Data error at batch 697: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 157.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1067])
Data error at batch 698: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 141.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1067])
Data error at batch 699: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 141.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1104])
Data error at batch 700: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 170.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1104])
Data error at batch 701: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 170.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1046])
Data error at batch 702: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 163.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1046])
Data error at batch 703: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 163.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1727])
Data error at batch 704: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1727])
Data error at batch 705: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1754])
Data error at batch 706: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 74.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1754])
Data error at batch 707: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 74.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1770])
Data error at batch 708: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 65.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1770])
Data error at batch 709: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 65.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1716])
Data error at batch 710: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 96.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1716])
Data error at batch 711: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 96.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 836])
Data error at batch 712: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 836])
Data error at batch 713: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 92.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 839])
Data error at batch 714: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 91.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 839])
Data error at batch 715: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 91.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 863])
Data error at batch 716: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 863])
Data error at batch 717: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 830])
Data error at batch 718: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 100.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 830])
Data error at batch 719: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 100.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1052])
Data error at batch 720: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 181.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1052])
Data error at batch 721: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 181.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1074])
Data error at batch 722: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 166.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1074])
Data error at batch 723: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 166.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1084])
Data error at batch 724: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1084])
Data error at batch 725: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1060])
Data error at batch 726: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 174.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1060])
Data error at batch 727: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 174.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 678])
Data error at batch 728: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 69.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 678])
Data error at batch 729: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 69.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 699])
Data error at batch 730: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 699])
Data error at batch 731: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 671])
Data error at batch 732: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 671])
Data error at batch 733: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 662])
Data error at batch 734: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 662])
Data error at batch 735: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1098])
Data error at batch 736: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1098])
Data error at batch 737: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1081])
Data error at batch 738: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 159.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1081])
Data error at batch 739: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 159.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1140])
Data error at batch 740: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 124.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1140])
Data error at batch 741: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 124.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1073])
Data error at batch 742: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 166.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1073])
Data error at batch 743: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 166.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1475])
Data error at batch 744: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 161.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1475])
Data error at batch 745: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 128.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1456])
Data error at batch 746: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 81.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1456])
Data error at batch 747: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 81.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1503])
Data error at batch 748: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 45.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1503])
Data error at batch 749: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 45.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1472])
Data error at batch 750: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 57.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1472])
Data error at batch 751: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 57.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 858])
Data error at batch 752: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 111.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 858])
Data error at batch 753: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 110.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 878])
Data error at batch 754: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 156.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 878])
Data error at batch 755: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 156.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 901])
Data error at batch 756: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 138.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 901])
Data error at batch 757: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 138.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 886])
Data error at batch 758: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 147.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 886])
Data error at batch 759: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 147.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1522])
Data error at batch 760: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1522])
Data error at batch 761: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1561])
Data error at batch 762: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 129.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1561])
Data error at batch 763: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 122.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1582])
Data error at batch 764: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 107.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1582])
Data error at batch 765: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 107.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1544])
Data error at batch 766: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1544])
Data error at batch 767: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1273])
Data error at batch 768: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 186.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1273])
Data error at batch 769: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 186.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1291])
Data error at batch 770: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 202.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1291])
Data error at batch 771: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 202.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1291])
Data error at batch 772: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 202.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1291])
Data error at batch 773: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 202.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1258])
Data error at batch 774: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 190.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1258])
Data error at batch 775: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 190.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1441])
Data error at batch 776: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 131.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1441])
Data error at batch 777: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 131.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1456])
Data error at batch 778: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 124.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1456])
Data error at batch 779: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 124.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1494])
Data error at batch 780: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 101.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1494])
Data error at batch 781: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 101.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1460])
Data error at batch 782: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 122.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1460])
Data error at batch 783: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 122.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1921])
Data error at batch 784: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 91.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1921])
Data error at batch 785: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 97.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1912])
Data error at batch 786: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 81.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1912])
Data error at batch 787: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 59.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1953])
Data error at batch 788: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 69.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1953])
Data error at batch 789: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 42.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1911])
Data error at batch 790: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 96.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1911])
Data error at batch 791: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 96.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1186])
Data error at batch 792: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 162.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1186])
Data error at batch 793: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 162.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1201])
Data error at batch 794: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 157.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1201])
Data error at batch 795: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 157.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1221])
Data error at batch 796: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 146.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1221])
Data error at batch 797: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 146.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1185])
Data error at batch 798: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 165.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1185])
Data error at batch 799: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 165.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1270])
Data error at batch 800: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 114.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1270])
Data error at batch 801: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 114.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1269])
Data error at batch 802: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 117.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1269])
Data error at batch 803: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 117.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1315])
Data error at batch 804: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1315])
Data error at batch 805: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1276])
Data error at batch 806: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 112.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1276])
Data error at batch 807: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 112.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1042])
Data error at batch 808: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1042])
Data error at batch 809: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1034])
Data error at batch 810: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 170.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1034])
Data error at batch 811: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 170.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1090])
Data error at batch 812: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 131.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1090])
Data error at batch 813: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 131.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1028])
Data error at batch 814: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 174.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1028])
Data error at batch 815: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 174.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1025])
Data error at batch 816: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 175.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1025])
Data error at batch 817: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 175.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1059])
Data error at batch 818: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 131.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1059])
Data error at batch 819: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 131.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1054])
Data error at batch 820: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 134.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1054])
Data error at batch 821: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 134.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1027])
Data error at batch 822: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 174.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1027])
Data error at batch 823: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 174.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1235])
Data error at batch 824: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 138.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1235])
Data error at batch 825: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 138.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1232])
Data error at batch 826: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 138.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1232])
Data error at batch 827: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 138.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1296])
Data error at batch 828: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1296])
Data error at batch 829: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1239])
Data error at batch 830: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 136.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1239])
Data error at batch 831: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 136.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1243])
Data error at batch 832: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 133.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1243])
Data error at batch 833: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 133.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1236])
Data error at batch 834: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 135.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1236])
Data error at batch 835: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 135.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1254])
Data error at batch 836: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1254])
Data error at batch 837: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1222])
Data error at batch 838: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1222])
Data error at batch 839: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 726])
Data error at batch 840: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 726])
Data error at batch 841: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 727])
Data error at batch 842: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 727])
Data error at batch 843: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 748])
Data error at batch 844: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 748])
Data error at batch 845: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 739])
Data error at batch 846: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 69.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 739])
Data error at batch 847: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 69.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1238])
Data error at batch 848: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 134.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1238])
Data error at batch 849: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 134.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1252])
Data error at batch 850: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 122.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1252])
Data error at batch 851: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 122.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1271])
Data error at batch 852: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 116.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1271])
Data error at batch 853: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 116.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1239])
Data error at batch 854: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 136.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1239])
Data error at batch 855: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 136.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 995])
Data error at batch 856: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 995])
Data error at batch 857: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1007])
Data error at batch 858: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1007])
Data error at batch 859: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1060])
Data error at batch 860: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1060])
Data error at batch 861: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1023])
Data error at batch 862: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 50.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1023])
Data error at batch 863: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 50.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1144])
Data error at batch 864: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 119.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1144])
Data error at batch 865: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 119.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1151])
Data error at batch 866: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 181.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1151])
Data error at batch 867: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 181.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1173])
Data error at batch 868: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1173])
Data error at batch 869: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1156])
Data error at batch 870: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 179.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1156])
Data error at batch 871: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 179.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1277])
Data error at batch 872: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 113.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1277])
Data error at batch 873: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 113.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1279])
Data error at batch 874: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 112.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1279])
Data error at batch 875: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 112.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1319])
Data error at batch 876: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 107.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1319])
Data error at batch 877: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 107.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1257])
Data error at batch 878: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 122.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1257])
Data error at batch 879: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 122.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1368])
Data error at batch 880: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 238.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1368])
Data error at batch 881: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 238.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1387])
Data error at batch 882: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 229.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1387])
Data error at batch 883: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 229.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1384])
Data error at batch 884: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 230.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1384])
Data error at batch 885: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 230.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1354])
Data error at batch 886: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 156.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1354])
Data error at batch 887: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 156.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1382])
Data error at batch 888: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 231.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1382])
Data error at batch 889: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 231.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1396])
Data error at batch 890: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 225.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1396])
Data error at batch 891: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 225.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1405])
Data error at batch 892: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 221.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1405])
Data error at batch 893: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 221.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1366])
Data error at batch 894: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 238.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1366])
Data error at batch 895: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 238.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1767])
Data error at batch 896: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 151.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1767])
Data error at batch 897: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 151.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1750])
Data error at batch 898: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1750])
Data error at batch 899: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1789])
Data error at batch 900: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1789])
Data error at batch 901: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1767])
Data error at batch 902: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 151.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1767])
Data error at batch 903: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 151.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 851])
Data error at batch 904: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 33.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 851])
Data error at batch 905: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 33.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 853])
Data error at batch 906: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 32.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 853])
Data error at batch 907: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 32.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 878])
Data error at batch 908: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 104.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 878])
Data error at batch 909: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 104.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 874])
Data error at batch 910: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 110.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 874])
Data error at batch 911: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 110.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1246])
Data error at batch 912: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 125.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1246])
Data error at batch 913: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 125.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1259])
Data error at batch 914: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1259])
Data error at batch 915: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1302])
Data error at batch 916: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 117.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1302])
Data error at batch 917: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 117.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1228])
Data error at batch 918: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 140.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1228])
Data error at batch 919: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 140.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 811])
Data error at batch 920: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 811])
Data error at batch 921: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 842])
Data error at batch 922: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 842])
Data error at batch 923: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 854])
Data error at batch 924: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 32.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 854])
Data error at batch 925: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 32.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 802])
Data error at batch 926: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 802])
Data error at batch 927: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 780])
Data error at batch 928: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 780])
Data error at batch 929: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 773])
Data error at batch 930: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 62.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 773])
Data error at batch 931: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 62.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 813])
Data error at batch 932: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 813])
Data error at batch 933: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 777])
Data error at batch 934: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 777])
Data error at batch 935: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1525])
Data error at batch 936: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 222.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1525])
Data error at batch 937: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 222.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1546])
Data error at batch 938: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 216.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1546])
Data error at batch 939: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 216.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1561])
Data error at batch 940: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 210.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1561])
Data error at batch 941: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 210.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1510])
Data error at batch 942: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 226.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1510])
Data error at batch 943: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 226.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1469])
Data error at batch 944: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 245.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1469])
Data error at batch 945: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 245.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1467])
Data error at batch 946: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 246.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1467])
Data error at batch 947: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 246.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1491])
Data error at batch 948: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 233.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1491])
Data error at batch 949: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 233.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1449])
Data error at batch 950: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 201.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1449])
Data error at batch 951: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 201.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 888])
Data error at batch 952: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 92.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 888])
Data error at batch 953: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 92.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 904])
Data error at batch 954: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 103.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 904])
Data error at batch 955: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 103.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 915])
Data error at batch 956: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 95.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 915])
Data error at batch 957: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 95.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 886])
Data error at batch 958: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 93.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 886])
Data error at batch 959: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 93.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1329])
Data error at batch 960: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 97.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1329])
Data error at batch 961: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 97.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1345])
Data error at batch 962: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1345])
Data error at batch 963: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1361])
Data error at batch 964: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 156.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1361])
Data error at batch 965: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 156.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1315])
Data error at batch 966: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1315])
Data error at batch 967: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 761])
Data error at batch 968: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 52.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 761])
Data error at batch 969: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 52.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 767])
Data error at batch 970: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 767])
Data error at batch 971: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 807])
Data error at batch 972: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 807])
Data error at batch 973: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 772])
Data error at batch 974: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 62.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 772])
Data error at batch 975: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 62.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1061])
Data error at batch 976: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1061])
Data error at batch 977: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1075])
Data error at batch 978: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1075])
Data error at batch 979: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1098])
Data error at batch 980: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1098])
Data error at batch 981: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1049])
Data error at batch 982: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1049])
Data error at batch 983: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 900])
Data error at batch 984: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 105.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 900])
Data error at batch 985: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 105.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 890])
Data error at batch 986: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 91.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 890])
Data error at batch 987: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 91.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 920])
Data error at batch 988: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 91.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 920])
Data error at batch 989: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 91.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 872])
Data error at batch 990: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 53.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 872])
Data error at batch 991: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 53.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1610])
Data error at batch 992: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 189.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1610])
Data error at batch 993: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 189.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1592])
Data error at batch 994: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 195.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1592])
Data error at batch 995: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 195.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1631])
Data error at batch 996: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 182.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1631])
Data error at batch 997: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 182.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1607])
Data error at batch 998: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 190.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1607])
Data error at batch 999: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 190.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1742])
Data error at batch 1000: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 164.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1742])
Data error at batch 1001: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 164.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1733])
Data error at batch 1002: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 168.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1733])
Data error at batch 1003: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 168.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1767])
Data error at batch 1004: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 155.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1767])
Data error at batch 1005: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 155.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1735])
Data error at batch 1006: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 168.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1735])
Data error at batch 1007: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 168.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1294])
Data error at batch 1008: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 100.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1294])
Data error at batch 1009: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 120.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1329])
Data error at batch 1010: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 95.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1329])
Data error at batch 1011: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 95.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1340])
Data error at batch 1012: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1340])
Data error at batch 1013: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1295])
Data error at batch 1014: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1295])
Data error at batch 1015: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1069])
Data error at batch 1016: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 145.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1069])
Data error at batch 1017: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 145.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1080])
Data error at batch 1018: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 133.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1080])
Data error at batch 1019: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 133.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1127])
Data error at batch 1020: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1127])
Data error at batch 1021: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1063])
Data error at batch 1022: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1063])
Data error at batch 1023: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1920])
Data error at batch 1024: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 97.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1920])
Data error at batch 1025: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 97.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1974])
Data error at batch 1026: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 74.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1974])
Data error at batch 1027: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 74.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1986])
Data error at batch 1028: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 60.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1986])
Data error at batch 1029: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 60.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1950])
Data error at batch 1030: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 86.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1950])
Data error at batch 1031: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 86.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 607])
Data error at batch 1032: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 49.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 607])
Data error at batch 1033: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 37.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 604])
Data error at batch 1034: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 42.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 604])
Data error at batch 1035: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 42.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 647])
Data error at batch 1036: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 647])
Data error at batch 1037: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 604])
Data error at batch 1038: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 42.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 604])
Data error at batch 1039: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 42.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1862])
Data error at batch 1040: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 120.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1862])
Data error at batch 1041: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 120.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1872])
Data error at batch 1042: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 116.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1872])
Data error at batch 1043: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 116.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1947])
Data error at batch 1044: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 88.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1947])
Data error at batch 1045: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 88.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1887])
Data error at batch 1046: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 110.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1887])
Data error at batch 1047: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 110.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1895])
Data error at batch 1048: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 108.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1895])
Data error at batch 1049: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 108.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1935])
Data error at batch 1050: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 92.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1935])
Data error at batch 1051: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 92.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1926])
Data error at batch 1052: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 95.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1926])
Data error at batch 1053: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 95.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1906])
Data error at batch 1054: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 103.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1906])
Data error at batch 1055: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 103.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2388])
Data error at batch 1056: CUDA out of memory. Tried to allocate 52.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2388])
Data error at batch 1057: CUDA out of memory. Tried to allocate 52.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 131.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2412])
Data error at batch 1058: CUDA out of memory. Tried to allocate 52.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 126.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2412])
Data error at batch 1059: CUDA out of memory. Tried to allocate 52.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 126.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2407])
Data error at batch 1060: CUDA out of memory. Tried to allocate 52.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 127.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2407])
Data error at batch 1061: CUDA out of memory. Tried to allocate 52.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 127.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2372])
Data error at batch 1062: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 134.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2372])
Data error at batch 1063: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 134.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1983])
Data error at batch 1064: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 77.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1983])
Data error at batch 1065: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 77.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1962])
Data error at batch 1066: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 82.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1962])
Data error at batch 1067: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 82.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2010])
Data error at batch 1068: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2010])
Data error at batch 1069: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1954])
Data error at batch 1070: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1954])
Data error at batch 1071: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1549])
Data error at batch 1072: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 235.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1549])
Data error at batch 1073: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 235.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1595])
Data error at batch 1074: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 214.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1595])
Data error at batch 1075: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 214.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1587])
Data error at batch 1076: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 220.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1587])
Data error at batch 1077: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 220.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1547])
Data error at batch 1078: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 235.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1547])
Data error at batch 1079: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 235.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1701])
Data error at batch 1080: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 174.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1701])
Data error at batch 1081: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 174.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1704])
Data error at batch 1082: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 172.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1704])
Data error at batch 1083: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 172.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1714])
Data error at batch 1084: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 169.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1714])
Data error at batch 1085: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 169.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1705])
Data error at batch 1086: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 172.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1705])
Data error at batch 1087: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 172.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1405])
Data error at batch 1088: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 187.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1405])
Data error at batch 1089: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 187.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1427])
Data error at batch 1090: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.70 GiB is allocated by PyTorch, and 280.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1427])
Data error at batch 1091: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.70 GiB is allocated by PyTorch, and 280.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1424])
Data error at batch 1092: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.70 GiB is allocated by PyTorch, and 281.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1424])
Data error at batch 1093: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.70 GiB is allocated by PyTorch, and 281.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1385])
Data error at batch 1094: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 195.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1385])
Data error at batch 1095: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 195.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1475])
Data error at batch 1096: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 261.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1475])
Data error at batch 1097: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 261.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1515])
Data error at batch 1098: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 245.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1515])
Data error at batch 1099: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 245.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1489])
Data error at batch 1100: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 254.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1489])
Data error at batch 1101: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 254.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1479])
Data error at batch 1102: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 257.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1479])
Data error at batch 1103: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 257.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 766])
Data error at batch 1104: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 766])
Data error at batch 1105: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 779])
Data error at batch 1106: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 779])
Data error at batch 1107: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 799])
Data error at batch 1108: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 799])
Data error at batch 1109: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 761])
Data error at batch 1110: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 761])
Data error at batch 1111: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1966])
Data error at batch 1112: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 101.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1966])
Data error at batch 1113: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 101.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2002])
Data error at batch 1114: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 79.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2002])
Data error at batch 1115: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 79.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2027])
Data error at batch 1116: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2027])
Data error at batch 1117: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1985])
Data error at batch 1118: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 82.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1985])
Data error at batch 1119: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 82.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 763])
Data error at batch 1120: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 763])
Data error at batch 1121: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 828])
Data error at batch 1122: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 828])
Data error at batch 1123: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 824])
Data error at batch 1124: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 824])
Data error at batch 1125: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 803])
Data error at batch 1126: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 62.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 803])
Data error at batch 1127: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 62.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1564])
Data error at batch 1128: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 229.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1564])
Data error at batch 1129: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 229.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1569])
Data error at batch 1130: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 227.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1569])
Data error at batch 1131: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 227.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1607])
Data error at batch 1132: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 210.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1607])
Data error at batch 1133: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 210.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1586])
Data error at batch 1134: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 220.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1586])
Data error at batch 1135: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 220.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 712])
Data error at batch 1136: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 712])
Data error at batch 1137: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 698])
Data error at batch 1138: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 698])
Data error at batch 1139: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 753])
Data error at batch 1140: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 753])
Data error at batch 1141: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 731])
Data error at batch 1142: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 731])
Data error at batch 1143: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 856])
Data error at batch 1144: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 856])
Data error at batch 1145: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 905])
Data error at batch 1146: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 905])
Data error at batch 1147: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 908])
Data error at batch 1148: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 97.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 908])
Data error at batch 1149: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 97.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 853])
Data error at batch 1150: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 853])
Data error at batch 1151: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1357])
Data error at batch 1152: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1357])
Data error at batch 1153: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1348])
Data error at batch 1154: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1348])
Data error at batch 1155: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1374])
Data error at batch 1156: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 202.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1374])
Data error at batch 1157: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 202.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1330])
Data error at batch 1158: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1330])
Data error at batch 1159: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1767])
Data error at batch 1160: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 175.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1767])
Data error at batch 1161: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 175.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1793])
Data error at batch 1162: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 165.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1793])
Data error at batch 1163: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 165.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1785])
Data error at batch 1164: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 168.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1785])
Data error at batch 1165: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 168.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1754])
Data error at batch 1166: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1754])
Data error at batch 1167: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 713])
Data error at batch 1168: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 50.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 713])
Data error at batch 1169: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 50.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 739])
Data error at batch 1170: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 739])
Data error at batch 1171: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 751])
Data error at batch 1172: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 751])
Data error at batch 1173: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 711])
Data error at batch 1174: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 711])
Data error at batch 1175: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 752])
Data error at batch 1176: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 752])
Data error at batch 1177: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 733])
Data error at batch 1178: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 733])
Data error at batch 1179: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 753])
Data error at batch 1180: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 753])
Data error at batch 1181: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 705])
Data error at batch 1182: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 705])
Data error at batch 1183: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1584])
Data error at batch 1184: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 221.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1584])
Data error at batch 1185: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 221.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1606])
Data error at batch 1186: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 211.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1606])
Data error at batch 1187: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 211.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1612])
Data error at batch 1188: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 209.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1612])
Data error at batch 1189: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 209.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1564])
Data error at batch 1190: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 229.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1564])
Data error at batch 1191: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 229.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2131])
Data error at batch 1192: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 145.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2131])
Data error at batch 1193: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 37.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 125.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2177])
Data error at batch 1194: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 166.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2177])
Data error at batch 1195: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 166.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2208])
Data error at batch 1196: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 128.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2208])
Data error at batch 1197: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 128.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2142])
Data error at batch 1198: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 87.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2142])
Data error at batch 1199: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 132.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 652])
Data error at batch 1200: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 40.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 652])
Data error at batch 1201: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 38.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 663])
Data error at batch 1202: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 663])
Data error at batch 1203: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 687])
Data error at batch 1204: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 687])
Data error at batch 1205: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 658])
Data error at batch 1206: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 658])
Data error at batch 1207: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1309])
Data error at batch 1208: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 180.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1309])
Data error at batch 1209: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 180.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1312])
Data error at batch 1210: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 205.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1312])
Data error at batch 1211: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 205.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1332])
Data error at batch 1212: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 193.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1332])
Data error at batch 1213: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 193.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1304])
Data error at batch 1214: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 180.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1304])
Data error at batch 1215: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 180.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1108])
Data error at batch 1216: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 97.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1108])
Data error at batch 1217: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 97.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1106])
Data error at batch 1218: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1106])
Data error at batch 1219: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1124])
Data error at batch 1220: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1124])
Data error at batch 1221: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1099])
Data error at batch 1222: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 102.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1099])
Data error at batch 1223: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 102.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1235])
Data error at batch 1224: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1235])
Data error at batch 1225: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1270])
Data error at batch 1226: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 198.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1270])
Data error at batch 1227: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 198.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1263])
Data error at batch 1228: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 204.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1263])
Data error at batch 1229: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 204.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1204])
Data error at batch 1230: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1204])
Data error at batch 1231: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1597])
Data error at batch 1232: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 204.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1597])
Data error at batch 1233: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 204.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1584])
Data error at batch 1234: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 211.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1584])
Data error at batch 1235: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 211.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1632])
Data error at batch 1236: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 191.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1632])
Data error at batch 1237: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 191.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1590])
Data error at batch 1238: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 206.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1590])
Data error at batch 1239: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 206.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 762])
Data error at batch 1240: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 36.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 762])
Data error at batch 1241: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 766])
Data error at batch 1242: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 39.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 766])
Data error at batch 1243: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 39.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 774])
Data error at batch 1244: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 79.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 774])
Data error at batch 1245: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 79.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 740])
Data error at batch 1246: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 740])
Data error at batch 1247: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1225])
Data error at batch 1248: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1225])
Data error at batch 1249: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1268])
Data error at batch 1250: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 199.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1268])
Data error at batch 1251: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 199.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1277])
Data error at batch 1252: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 197.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1277])
Data error at batch 1253: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 197.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1229])
Data error at batch 1254: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 92.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1229])
Data error at batch 1255: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 92.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1103])
Data error at batch 1256: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 100.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1103])
Data error at batch 1257: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 100.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1068])
Data error at batch 1258: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 123.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1068])
Data error at batch 1259: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 123.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1099])
Data error at batch 1260: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 102.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1099])
Data error at batch 1261: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 102.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1089])
Data error at batch 1262: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 107.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1089])
Data error at batch 1263: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 107.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1122])
Data error at batch 1264: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 81.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1122])
Data error at batch 1265: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 81.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1139])
Data error at batch 1266: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1139])
Data error at batch 1267: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1160])
Data error at batch 1268: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 133.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1160])
Data error at batch 1269: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 133.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1124])
Data error at batch 1270: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1124])
Data error at batch 1271: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2317])
Data error at batch 1272: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 172.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2317])
Data error at batch 1273: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 172.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2364])
Data error at batch 1274: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 158.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2364])
Data error at batch 1275: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 158.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2378])
Data error at batch 1276: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 151.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2378])
Data error at batch 1277: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 151.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2348])
Data error at batch 1278: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 162.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2348])
Data error at batch 1279: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 162.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 977])
Data error at batch 1280: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 70.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 977])
Data error at batch 1281: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 69.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1016])
Data error at batch 1282: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 55.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1016])
Data error at batch 1283: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 55.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1021])
Data error at batch 1284: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 53.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1021])
Data error at batch 1285: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 53.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 983])
Data error at batch 1286: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 62.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 983])
Data error at batch 1287: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 62.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1418])
Data error at batch 1288: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 108.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1418])
Data error at batch 1289: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 108.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1429])
Data error at batch 1290: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 97.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1429])
Data error at batch 1291: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 97.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1439])
Data error at batch 1292: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 92.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1439])
Data error at batch 1293: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 92.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1407])
Data error at batch 1294: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 108.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1407])
Data error at batch 1295: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 108.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 989])
Data error at batch 1296: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 95.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 989])
Data error at batch 1297: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 59.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1013])
Data error at batch 1298: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 82.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1013])
Data error at batch 1299: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 82.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1035])
Data error at batch 1300: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 244.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1035])
Data error at batch 1301: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 260.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 980])
Data error at batch 1302: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 113.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 980])
Data error at batch 1303: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 113.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1428])
Data error at batch 1304: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 115.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1428])
Data error at batch 1305: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 115.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1439])
Data error at batch 1306: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 110.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1439])
Data error at batch 1307: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 110.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1474])
Data error at batch 1308: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1474])
Data error at batch 1309: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1424])
Data error at batch 1310: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 117.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1424])
Data error at batch 1311: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 117.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 902])
Data error at batch 1312: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 902])
Data error at batch 1313: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 902])
Data error at batch 1314: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 902])
Data error at batch 1315: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 910])
Data error at batch 1316: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 131.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 910])
Data error at batch 1317: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 131.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 880])
Data error at batch 1318: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 154.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 880])
Data error at batch 1319: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 154.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1641])
Data error at batch 1320: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 102.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1641])
Data error at batch 1321: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 102.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1685])
Data error at batch 1322: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 139.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1685])
Data error at batch 1323: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 120.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1713])
Data error at batch 1324: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 100.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1713])
Data error at batch 1325: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 79.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1674])
Data error at batch 1326: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1674])
Data error at batch 1327: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1438])
Data error at batch 1328: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 140.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1438])
Data error at batch 1329: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 140.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1460])
Data error at batch 1330: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1460])
Data error at batch 1331: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1479])
Data error at batch 1332: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 118.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1479])
Data error at batch 1333: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 118.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1421])
Data error at batch 1334: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 118.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1421])
Data error at batch 1335: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 118.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1351])
Data error at batch 1336: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 156.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1351])
Data error at batch 1337: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 156.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1383])
Data error at batch 1338: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 134.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1383])
Data error at batch 1339: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 134.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1395])
Data error at batch 1340: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1395])
Data error at batch 1341: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1361])
Data error at batch 1342: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 151.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1361])
Data error at batch 1343: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 151.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 835])
Data error at batch 1344: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 835])
Data error at batch 1345: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 824])
Data error at batch 1346: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 90.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 824])
Data error at batch 1347: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 90.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 872])
Data error at batch 1348: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 99.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 872])
Data error at batch 1349: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 99.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 833])
Data error at batch 1350: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 79.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 833])
Data error at batch 1351: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 79.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1540])
Data error at batch 1352: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1540])
Data error at batch 1353: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1553])
Data error at batch 1354: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1553])
Data error at batch 1355: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1596])
Data error at batch 1356: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 131.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1596])
Data error at batch 1357: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 131.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1550])
Data error at batch 1358: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 154.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1550])
Data error at batch 1359: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 154.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 840])
Data error at batch 1360: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 72.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 840])
Data error at batch 1361: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 72.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 835])
Data error at batch 1362: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 835])
Data error at batch 1363: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 870])
Data error at batch 1364: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 101.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 870])
Data error at batch 1365: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 101.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 851])
Data error at batch 1366: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 851])
Data error at batch 1367: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1707])
Data error at batch 1368: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 81.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1707])
Data error at batch 1369: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 81.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1743])
Data error at batch 1370: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1743])
Data error at batch 1371: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1724])
Data error at batch 1372: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1724])
Data error at batch 1373: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1687])
Data error at batch 1374: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1687])
Data error at batch 1375: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1353])
Data error at batch 1376: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 240.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1353])
Data error at batch 1377: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 240.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1339])
Data error at batch 1378: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 246.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1339])
Data error at batch 1379: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 246.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1360])
Data error at batch 1380: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 235.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1360])
Data error at batch 1381: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 235.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1313])
Data error at batch 1382: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 172.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1313])
Data error at batch 1383: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 172.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1210])
Data error at batch 1384: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 181.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1210])
Data error at batch 1385: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 181.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1217])
Data error at batch 1386: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 223.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1217])
Data error at batch 1387: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 223.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1245])
Data error at batch 1388: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 209.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1245])
Data error at batch 1389: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 209.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1203])
Data error at batch 1390: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 186.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1203])
Data error at batch 1391: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 186.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 781])
Data error at batch 1392: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 99.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 781])
Data error at batch 1393: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 99.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 829])
Data error at batch 1394: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 93.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 829])
Data error at batch 1395: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 93.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 833])
Data error at batch 1396: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 89.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 833])
Data error at batch 1397: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 89.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 804])
Data error at batch 1398: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 80.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 804])
Data error at batch 1399: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 80.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 834])
Data error at batch 1400: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 89.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 834])
Data error at batch 1401: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 89.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 816])
Data error at batch 1402: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 110.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 816])
Data error at batch 1403: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 110.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 834])
Data error at batch 1404: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 89.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 834])
Data error at batch 1405: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 89.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 810])
Data error at batch 1406: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 810])
Data error at batch 1407: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 854])
Data error at batch 1408: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 854])
Data error at batch 1409: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 916])
Data error at batch 1410: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 104.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 916])
Data error at batch 1411: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 104.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 885])
Data error at batch 1412: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 885])
Data error at batch 1413: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 855])
Data error at batch 1414: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 76.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 855])
Data error at batch 1415: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 76.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1441])
Data error at batch 1416: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 199.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1441])
Data error at batch 1417: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 199.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1436])
Data error at batch 1418: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 201.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1436])
Data error at batch 1419: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 201.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1466])
Data error at batch 1420: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1466])
Data error at batch 1421: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1411])
Data error at batch 1422: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 211.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1411])
Data error at batch 1423: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 211.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 962])
Data error at batch 1424: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 90.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 962])
Data error at batch 1425: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 90.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 955])
Data error at batch 1426: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 955])
Data error at batch 1427: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 986])
Data error at batch 1428: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 174.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 986])
Data error at batch 1429: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 174.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 963])
Data error at batch 1430: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 89.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 963])
Data error at batch 1431: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 89.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1759])
Data error at batch 1432: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1759])
Data error at batch 1433: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1758])
Data error at batch 1434: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1758])
Data error at batch 1435: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1784])
Data error at batch 1436: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 43.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1784])
Data error at batch 1437: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 43.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1761])
Data error at batch 1438: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1761])
Data error at batch 1439: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1277])
Data error at batch 1440: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 193.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1277])
Data error at batch 1441: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 193.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1290])
Data error at batch 1442: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 179.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1290])
Data error at batch 1443: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 179.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1310])
Data error at batch 1444: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 172.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1310])
Data error at batch 1445: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 172.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1250])
Data error at batch 1446: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 204.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1250])
Data error at batch 1447: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 204.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1404])
Data error at batch 1448: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 213.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1404])
Data error at batch 1449: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 213.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1401])
Data error at batch 1450: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 214.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1401])
Data error at batch 1451: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 214.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1412])
Data error at batch 1452: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 210.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1412])
Data error at batch 1453: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 210.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1397])
Data error at batch 1454: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 216.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1397])
Data error at batch 1455: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 216.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 811])
Data error at batch 1456: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 114.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 811])
Data error at batch 1457: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 114.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 840])
Data error at batch 1458: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 840])
Data error at batch 1459: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 839])
Data error at batch 1460: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 839])
Data error at batch 1461: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 809])
Data error at batch 1462: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 809])
Data error at batch 1463: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 635])
Data error at batch 1464: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 62.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 635])
Data error at batch 1465: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 62.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 657])
Data error at batch 1466: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 657])
Data error at batch 1467: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 690])
Data error at batch 1468: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 59.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 690])
Data error at batch 1469: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 59.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 627])
Data error at batch 1470: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 37.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 627])
Data error at batch 1471: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 37.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1359])
Data error at batch 1472: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 237.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1359])
Data error at batch 1473: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 237.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1398])
Data error at batch 1474: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 215.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1398])
Data error at batch 1475: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 215.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1434])
Data error at batch 1476: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 202.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1434])
Data error at batch 1477: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 202.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1365])
Data error at batch 1478: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 235.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1365])
Data error at batch 1479: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 235.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 752])
Data error at batch 1480: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 752])
Data error at batch 1481: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 760])
Data error at batch 1482: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 760])
Data error at batch 1483: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 764])
Data error at batch 1484: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 764])
Data error at batch 1485: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 745])
Data error at batch 1486: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 745])
Data error at batch 1487: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1048])
Data error at batch 1488: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 177.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1048])
Data error at batch 1489: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 177.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1046])
Data error at batch 1490: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 179.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1046])
Data error at batch 1491: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 179.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1082])
Data error at batch 1492: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 156.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1082])
Data error at batch 1493: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 156.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1040])
Data error at batch 1494: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 182.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1040])
Data error at batch 1495: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 182.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1461])
Data error at batch 1496: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 190.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1461])
Data error at batch 1497: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 190.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1457])
Data error at batch 1498: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 192.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1457])
Data error at batch 1499: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 192.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1464])
Data error at batch 1500: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 189.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1464])
Data error at batch 1501: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 189.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1438])
Data error at batch 1502: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 201.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1438])
Data error at batch 1503: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 201.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 892])
Data error at batch 1504: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 87.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 892])
Data error at batch 1505: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 87.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 928])
Data error at batch 1506: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 97.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 928])
Data error at batch 1507: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 97.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 939])
Data error at batch 1508: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 105.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 939])
Data error at batch 1509: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 105.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 888])
Data error at batch 1510: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 89.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 888])
Data error at batch 1511: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 89.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1030])
Data error at batch 1512: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 144.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1030])
Data error at batch 1513: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 144.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1030])
Data error at batch 1514: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 144.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1030])
Data error at batch 1515: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 144.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1084])
Data error at batch 1516: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 155.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1084])
Data error at batch 1517: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 155.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1037])
Data error at batch 1518: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 141.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1037])
Data error at batch 1519: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 141.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1286])
Data error at batch 1520: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 180.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1286])
Data error at batch 1521: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 180.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1311])
Data error at batch 1522: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 173.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1311])
Data error at batch 1523: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 173.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1303])
Data error at batch 1524: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 176.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1303])
Data error at batch 1525: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 176.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1280])
Data error at batch 1526: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 189.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1280])
Data error at batch 1527: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 189.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1751])
Data error at batch 1528: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1751])
Data error at batch 1529: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1753])
Data error at batch 1530: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1753])
Data error at batch 1531: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1779])
Data error at batch 1532: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 43.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1779])
Data error at batch 1533: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 43.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1766])
Data error at batch 1534: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1766])
Data error at batch 1535: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 566])
Data error at batch 1536: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 566])
Data error at batch 1537: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 554])
Data error at batch 1538: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 36.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 554])
Data error at batch 1539: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 36.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 583])
Data error at batch 1540: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 583])
Data error at batch 1541: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 553])
Data error at batch 1542: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 37.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 553])
Data error at batch 1543: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 37.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1073])
Data error at batch 1544: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 161.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1073])
Data error at batch 1545: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 161.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1080])
Data error at batch 1546: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 157.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1080])
Data error at batch 1547: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 157.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1086])
Data error at batch 1548: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1086])
Data error at batch 1549: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1039])
Data error at batch 1550: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 183.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1039])
Data error at batch 1551: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 183.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1227])
Data error at batch 1552: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 218.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1227])
Data error at batch 1553: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 218.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1248])
Data error at batch 1554: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 205.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1248])
Data error at batch 1555: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 205.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1285])
Data error at batch 1556: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1285])
Data error at batch 1557: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1245])
Data error at batch 1558: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 209.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1245])
Data error at batch 1559: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 209.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 856])
Data error at batch 1560: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 856])
Data error at batch 1561: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 847])
Data error at batch 1562: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 81.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 847])
Data error at batch 1563: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 81.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 872])
Data error at batch 1564: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 872])
Data error at batch 1565: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 859])
Data error at batch 1566: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 859])
Data error at batch 1567: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 672])
Data error at batch 1568: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 672])
Data error at batch 1569: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 710])
Data error at batch 1570: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 48.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 710])
Data error at batch 1571: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 48.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 708])
Data error at batch 1572: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 708])
Data error at batch 1573: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 670])
Data error at batch 1574: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 670])
Data error at batch 1575: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1184])
Data error at batch 1576: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1184])
Data error at batch 1577: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1159])
Data error at batch 1578: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1159])
Data error at batch 1579: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1194])
Data error at batch 1580: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 83.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1194])
Data error at batch 1581: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 83.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1158])
Data error at batch 1582: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 99.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1158])
Data error at batch 1583: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 99.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1370])
Data error at batch 1584: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 230.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1370])
Data error at batch 1585: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 230.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1374])
Data error at batch 1586: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 229.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1374])
Data error at batch 1587: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 229.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1395])
Data error at batch 1588: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 216.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1395])
Data error at batch 1589: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 216.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1364])
Data error at batch 1590: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 233.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1364])
Data error at batch 1591: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 233.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1913])
Data error at batch 1592: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 111.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1913])
Data error at batch 1593: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1962])
Data error at batch 1594: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 200.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1962])
Data error at batch 1595: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 172.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1975])
Data error at batch 1596: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 74.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1975])
Data error at batch 1597: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 74.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1926])
Data error at batch 1598: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 95.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1926])
Data error at batch 1599: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 95.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 842])
Data error at batch 1600: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 70.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 842])
Data error at batch 1601: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 70.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 853])
Data error at batch 1602: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 36.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 853])
Data error at batch 1603: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 36.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 850])
Data error at batch 1604: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 37.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 850])
Data error at batch 1605: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 37.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 826])
Data error at batch 1606: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 55.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 826])
Data error at batch 1607: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 55.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 672])
Data error at batch 1608: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 57.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 672])
Data error at batch 1609: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 57.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 732])
Data error at batch 1610: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 93.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 732])
Data error at batch 1611: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 93.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 715])
Data error at batch 1612: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 39.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 715])
Data error at batch 1613: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 39.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 666])
Data error at batch 1614: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 37.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 666])
Data error at batch 1615: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 36.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 728])
Data error at batch 1616: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 728])
Data error at batch 1617: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 737])
Data error at batch 1618: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 76.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 737])
Data error at batch 1619: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 76.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 780])
Data error at batch 1620: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 780])
Data error at batch 1621: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 714])
Data error at batch 1622: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 53.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 714])
Data error at batch 1623: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 53.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1491])
Data error at batch 1624: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 43.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1491])
Data error at batch 1625: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 44.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1487])
Data error at batch 1626: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 44.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1487])
Data error at batch 1627: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 44.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1531])
Data error at batch 1628: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 62.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1531])
Data error at batch 1629: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 62.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1485])
Data error at batch 1630: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1485])
Data error at batch 1631: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 718])
Data error at batch 1632: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 37.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 718])
Data error at batch 1633: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 37.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 705])
Data error at batch 1634: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 705])
Data error at batch 1635: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 742])
Data error at batch 1636: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 742])
Data error at batch 1637: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 704])
Data error at batch 1638: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 704])
Data error at batch 1639: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1444])
Data error at batch 1640: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1444])
Data error at batch 1641: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1448])
Data error at batch 1642: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 104.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1448])
Data error at batch 1643: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 104.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1461])
Data error at batch 1644: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1461])
Data error at batch 1645: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1428])
Data error at batch 1646: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 113.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1428])
Data error at batch 1647: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 113.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 964])
Data error at batch 1648: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 124.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 964])
Data error at batch 1649: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 124.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 950])
Data error at batch 1650: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 133.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 950])
Data error at batch 1651: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 133.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 988])
Data error at batch 1652: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 113.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 988])
Data error at batch 1653: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 113.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 956])
Data error at batch 1654: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 956])
Data error at batch 1655: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 529])
Data error at batch 1656: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 529])
Data error at batch 1657: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 535])
Data error at batch 1658: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 41.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 535])
Data error at batch 1659: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 41.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 551])
Data error at batch 1660: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 551])
Data error at batch 1661: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 544])
Data error at batch 1662: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 544])
Data error at batch 1663: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1496])
Data error at batch 1664: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1496])
Data error at batch 1665: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1489])
Data error at batch 1666: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 72.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1489])
Data error at batch 1667: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 72.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1511])
Data error at batch 1668: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1511])
Data error at batch 1669: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1469])
Data error at batch 1670: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1469])
Data error at batch 1671: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1054])
Data error at batch 1672: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 174.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1054])
Data error at batch 1673: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 174.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1048])
Data error at batch 1674: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 177.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1048])
Data error at batch 1675: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 177.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1072])
Data error at batch 1676: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 160.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1072])
Data error at batch 1677: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 160.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1051])
Data error at batch 1678: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 175.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1051])
Data error at batch 1679: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 175.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1568])
Data error at batch 1680: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 189.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1568])
Data error at batch 1681: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 162.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1554])
Data error at batch 1682: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1554])
Data error at batch 1683: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1614])
Data error at batch 1684: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 115.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1614])
Data error at batch 1685: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 115.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1569])
Data error at batch 1686: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 141.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1569])
Data error at batch 1687: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 141.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1696])
Data error at batch 1688: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 100.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1696])
Data error at batch 1689: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 81.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1672])
Data error at batch 1690: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 90.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1672])
Data error at batch 1691: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 90.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1732])
Data error at batch 1692: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 43.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1732])
Data error at batch 1693: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 71.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1679])
Data error at batch 1694: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 105.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1679])
Data error at batch 1695: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 105.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 756])
Data error at batch 1696: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 756])
Data error at batch 1697: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 761])
Data error at batch 1698: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 761])
Data error at batch 1699: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 778])
Data error at batch 1700: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 102.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 778])
Data error at batch 1701: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 102.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 758])
Data error at batch 1702: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 76.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 758])
Data error at batch 1703: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 76.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1826])
Data error at batch 1704: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 120.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1826])
Data error at batch 1705: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 106.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1850])
Data error at batch 1706: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 72.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1850])
Data error at batch 1707: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 101.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1852])
Data error at batch 1708: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 100.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1852])
Data error at batch 1709: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 100.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1825])
Data error at batch 1710: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 111.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1825])
Data error at batch 1711: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 111.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1759])
Data error at batch 1712: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 136.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1759])
Data error at batch 1713: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 136.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1776])
Data error at batch 1714: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 127.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1776])
Data error at batch 1715: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 127.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1779])
Data error at batch 1716: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 127.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1779])
Data error at batch 1717: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 127.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1730])
Data error at batch 1718: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 148.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1730])
Data error at batch 1719: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 148.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1385])
Data error at batch 1720: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 150.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1385])
Data error at batch 1721: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 150.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1393])
Data error at batch 1722: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 177.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1393])
Data error at batch 1723: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 177.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1417])
Data error at batch 1724: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 167.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1417])
Data error at batch 1725: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 167.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1389])
Data error at batch 1726: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 178.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1389])
Data error at batch 1727: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 178.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1443])
Data error at batch 1728: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 237.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1443])
Data error at batch 1729: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 237.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1445])
Data error at batch 1730: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 236.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1445])
Data error at batch 1731: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 236.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1458])
Data error at batch 1732: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 231.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1458])
Data error at batch 1733: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 231.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1401])
Data error at batch 1734: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 174.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1401])
Data error at batch 1735: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 174.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 850])
Data error at batch 1736: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 850])
Data error at batch 1737: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 825])
Data error at batch 1738: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 87.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 825])
Data error at batch 1739: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 87.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 842])
Data error at batch 1740: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 842])
Data error at batch 1741: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 819])
Data error at batch 1742: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 50.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 819])
Data error at batch 1743: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 50.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1170])
Data error at batch 1744: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 125.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1170])
Data error at batch 1745: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 125.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1187])
Data error at batch 1746: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 118.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1187])
Data error at batch 1747: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 118.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1227])
Data error at batch 1748: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1227])
Data error at batch 1749: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1162])
Data error at batch 1750: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 132.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1162])
Data error at batch 1751: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 132.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1313])
Data error at batch 1752: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 203.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1313])
Data error at batch 1753: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 203.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1307])
Data error at batch 1754: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 206.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1307])
Data error at batch 1755: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 206.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1338])
Data error at batch 1756: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 190.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1338])
Data error at batch 1757: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 190.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1305])
Data error at batch 1758: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 207.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1305])
Data error at batch 1759: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 207.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1148])
Data error at batch 1760: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1148])
Data error at batch 1761: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1165])
Data error at batch 1762: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1165])
Data error at batch 1763: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1179])
Data error at batch 1764: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 122.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1179])
Data error at batch 1765: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 122.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1160])
Data error at batch 1766: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 133.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1160])
Data error at batch 1767: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 133.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 873])
Data error at batch 1768: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 873])
Data error at batch 1769: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 895])
Data error at batch 1770: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 895])
Data error at batch 1771: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 887])
Data error at batch 1772: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 887])
Data error at batch 1773: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 875])
Data error at batch 1774: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 104.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 875])
Data error at batch 1775: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 104.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1096])
Data error at batch 1776: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 172.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1096])
Data error at batch 1777: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 172.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1134])
Data error at batch 1778: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1134])
Data error at batch 1779: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1139])
Data error at batch 1780: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 144.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1139])
Data error at batch 1781: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 144.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1098])
Data error at batch 1782: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1098])
Data error at batch 1783: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1729])
Data error at batch 1784: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 135.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1729])
Data error at batch 1785: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 135.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1741])
Data error at batch 1786: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1741])
Data error at batch 1787: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1784])
Data error at batch 1788: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 111.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1784])
Data error at batch 1789: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 111.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1728])
Data error at batch 1790: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1728])
Data error at batch 1791: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1413])
Data error at batch 1792: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 167.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1413])
Data error at batch 1793: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 167.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1436])
Data error at batch 1794: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 237.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1436])
Data error at batch 1795: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 237.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1446])
Data error at batch 1796: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 234.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1446])
Data error at batch 1797: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 234.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1412])
Data error at batch 1798: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 167.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1412])
Data error at batch 1799: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 167.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1212])
Data error at batch 1800: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1212])
Data error at batch 1801: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1258])
Data error at batch 1802: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1258])
Data error at batch 1803: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1244])
Data error at batch 1804: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1244])
Data error at batch 1805: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1236])
Data error at batch 1806: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 91.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1236])
Data error at batch 1807: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 91.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1579])
Data error at batch 1808: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 202.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1579])
Data error at batch 1809: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 202.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1596])
Data error at batch 1810: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 195.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1596])
Data error at batch 1811: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 195.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1573])
Data error at batch 1812: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 204.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1573])
Data error at batch 1813: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 204.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1555])
Data error at batch 1814: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 212.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1555])
Data error at batch 1815: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 212.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1523])
Data error at batch 1816: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 203.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1523])
Data error at batch 1817: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 203.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1565])
Data error at batch 1818: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 188.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1565])
Data error at batch 1819: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 188.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1576])
Data error at batch 1820: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 183.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1576])
Data error at batch 1821: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 183.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1538])
Data error at batch 1822: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 199.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1538])
Data error at batch 1823: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 199.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 997])
Data error at batch 1824: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 83.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 997])
Data error at batch 1825: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 169.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1031])
Data error at batch 1826: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 145.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1031])
Data error at batch 1827: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 145.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1038])
Data error at batch 1828: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 142.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1038])
Data error at batch 1829: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 142.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 991])
Data error at batch 1830: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 173.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 991])
Data error at batch 1831: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 173.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1221])
Data error at batch 1832: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 142.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1221])
Data error at batch 1833: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 142.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1228])
Data error at batch 1834: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1228])
Data error at batch 1835: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1253])
Data error at batch 1836: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 116.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1253])
Data error at batch 1837: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 116.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1219])
Data error at batch 1838: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1219])
Data error at batch 1839: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1488])
Data error at batch 1840: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 230.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1488])
Data error at batch 1841: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 230.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1494])
Data error at batch 1842: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 228.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1494])
Data error at batch 1843: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 228.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1549])
Data error at batch 1844: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 194.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1549])
Data error at batch 1845: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 194.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1490])
Data error at batch 1846: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 214.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1490])
Data error at batch 1847: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 214.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 776])
Data error at batch 1848: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 776])
Data error at batch 1849: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 789])
Data error at batch 1850: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 789])
Data error at batch 1851: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 830])
Data error at batch 1852: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 830])
Data error at batch 1853: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 772])
Data error at batch 1854: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 772])
Data error at batch 1855: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 724])
Data error at batch 1856: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 35.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 724])
Data error at batch 1857: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 35.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 754])
Data error at batch 1858: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 754])
Data error at batch 1859: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 761])
Data error at batch 1860: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 761])
Data error at batch 1861: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 734])
Data error at batch 1862: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 52.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 734])
Data error at batch 1863: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 52.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 831])
Data error at batch 1864: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 831])
Data error at batch 1865: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 864])
Data error at batch 1866: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 115.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 864])
Data error at batch 1867: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 115.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 857])
Data error at batch 1868: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 122.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 857])
Data error at batch 1869: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 122.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 848])
Data error at batch 1870: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 848])
Data error at batch 1871: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1112])
Data error at batch 1872: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 160.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1112])
Data error at batch 1873: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 160.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1089])
Data error at batch 1874: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1089])
Data error at batch 1875: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1127])
Data error at batch 1876: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 153.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1127])
Data error at batch 1877: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 153.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1080])
Data error at batch 1878: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 134.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1080])
Data error at batch 1879: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 134.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1922])
Data error at batch 1880: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 120.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1922])
Data error at batch 1881: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 29.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 93.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1955])
Data error at batch 1882: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 78.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1955])
Data error at batch 1883: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 147.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1954])
Data error at batch 1884: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 147.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1954])
Data error at batch 1885: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 147.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1907])
Data error at batch 1886: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 101.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1907])
Data error at batch 1887: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 101.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1417])
Data error at batch 1888: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 186.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1417])
Data error at batch 1889: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 200.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1463])
Data error at batch 1890: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 180.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1463])
Data error at batch 1891: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 180.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1495])
Data error at batch 1892: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 162.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1495])
Data error at batch 1893: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 162.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1420])
Data error at batch 1894: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 199.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1420])
Data error at batch 1895: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 199.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1121])
Data error at batch 1896: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 117.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1121])
Data error at batch 1897: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 117.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1158])
Data error at batch 1898: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 181.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1158])
Data error at batch 1899: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 181.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1204])
Data error at batch 1900: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 156.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1204])
Data error at batch 1901: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 156.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1127])
Data error at batch 1902: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 114.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1127])
Data error at batch 1903: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 114.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 932])
Data error at batch 1904: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 64.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 932])
Data error at batch 1905: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 64.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 948])
Data error at batch 1906: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 67.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 948])
Data error at batch 1907: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 67.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 967])
Data error at batch 1908: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 70.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 967])
Data error at batch 1909: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 935])
Data error at batch 1910: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 935])
Data error at batch 1911: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1416])
Data error at batch 1912: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 200.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1416])
Data error at batch 1913: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 200.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1400])
Data error at batch 1914: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 207.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1400])
Data error at batch 1915: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 207.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1464])
Data error at batch 1916: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 179.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1464])
Data error at batch 1917: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 179.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1396])
Data error at batch 1918: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 209.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1396])
Data error at batch 1919: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 209.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1013])
Data error at batch 1920: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 52.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1013])
Data error at batch 1921: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1028])
Data error at batch 1922: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 157.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1028])
Data error at batch 1923: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 156.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1022])
Data error at batch 1924: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1022])
Data error at batch 1925: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 994])
Data error at batch 1926: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 994])
Data error at batch 1927: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1160])
Data error at batch 1928: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 178.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1160])
Data error at batch 1929: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 178.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1148])
Data error at batch 1930: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 183.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1148])
Data error at batch 1931: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 183.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1187])
Data error at batch 1932: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 163.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1187])
Data error at batch 1933: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 163.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1144])
Data error at batch 1934: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 103.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1144])
Data error at batch 1935: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 103.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 645])
Data error at batch 1936: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 645])
Data error at batch 1937: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 659])
Data error at batch 1938: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 41.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 659])
Data error at batch 1939: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 41.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 665])
Data error at batch 1940: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 665])
Data error at batch 1941: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 650])
Data error at batch 1942: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 650])
Data error at batch 1943: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1029])
Data error at batch 1944: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1029])
Data error at batch 1945: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 174.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1013])
Data error at batch 1946: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 92.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1013])
Data error at batch 1947: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 92.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1048])
Data error at batch 1948: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 163.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1048])
Data error at batch 1949: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 163.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1002])
Data error at batch 1950: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 102.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1002])
Data error at batch 1951: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 102.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1117])
Data error at batch 1952: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 141.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1117])
Data error at batch 1953: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 141.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1121])
Data error at batch 1954: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 136.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1121])
Data error at batch 1955: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 136.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1142])
Data error at batch 1956: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 122.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1142])
Data error at batch 1957: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 122.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1104])
Data error at batch 1958: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 126.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1104])
Data error at batch 1959: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 126.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1213])
Data error at batch 1960: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 83.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1213])
Data error at batch 1961: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 83.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1245])
Data error at batch 1962: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 60.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1245])
Data error at batch 1963: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 60.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1254])
Data error at batch 1964: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 56.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1254])
Data error at batch 1965: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 56.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1218])
Data error at batch 1966: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 65.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1218])
Data error at batch 1967: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 65.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1093])
Data error at batch 1968: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 157.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1093])
Data error at batch 1969: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 157.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1118])
Data error at batch 1970: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 146.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1118])
Data error at batch 1971: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 146.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1138])
Data error at batch 1972: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1138])
Data error at batch 1973: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 153.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1106])
Data error at batch 1974: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 146.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1106])
Data error at batch 1975: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 146.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1118])
Data error at batch 1976: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 140.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1118])
Data error at batch 1977: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 140.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1129])
Data error at batch 1978: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 158.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1129])
Data error at batch 1979: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 158.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1120])
Data error at batch 1980: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1120])
Data error at batch 1981: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1107])
Data error at batch 1982: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 145.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1107])
Data error at batch 1983: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 145.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 704])
Data error at batch 1984: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 704])
Data error at batch 1985: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 672])
Data error at batch 1986: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 672])
Data error at batch 1987: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 714])
Data error at batch 1988: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 123.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 714])
Data error at batch 1989: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 123.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 677])
Data error at batch 1990: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 75.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 677])
Data error at batch 1991: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 75.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 768])
Data error at batch 1992: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 115.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 768])
Data error at batch 1993: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 115.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 766])
Data error at batch 1994: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 117.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 766])
Data error at batch 1995: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 117.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 774])
Data error at batch 1996: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 774])
Data error at batch 1997: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 752])
Data error at batch 1998: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 103.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 752])
Data error at batch 1999: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 103.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 860])
Data error at batch 2000: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 860])
Data error at batch 2001: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 872])
Data error at batch 2002: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 145.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 872])
Data error at batch 2003: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 145.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 888])
Data error at batch 2004: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 136.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 888])
Data error at batch 2005: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 136.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 841])
Data error at batch 2006: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 93.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 841])
Data error at batch 2007: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 93.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1213])
Data error at batch 2008: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 83.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1213])
Data error at batch 2009: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 83.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1192])
Data error at batch 2010: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 90.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1192])
Data error at batch 2011: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 90.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1207])
Data error at batch 2012: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 85.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1207])
Data error at batch 2013: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 85.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1172])
Data error at batch 2014: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 110.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1172])
Data error at batch 2015: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 110.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 487])
Data error at batch 2016: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 37.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 487])
Data error at batch 2017: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 26.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 526])
Data error at batch 2018: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 526])
Data error at batch 2019: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 521])
Data error at batch 2020: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 521])
Data error at batch 2021: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 490])
Data error at batch 2022: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 24.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 490])
Data error at batch 2023: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 24.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1071])
Data error at batch 2024: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 168.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1071])
Data error at batch 2025: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 168.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1065])
Data error at batch 2026: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 173.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1065])
Data error at batch 2027: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 173.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1071])
Data error at batch 2028: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 168.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1071])
Data error at batch 2029: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 168.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1041])
Data error at batch 2030: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 144.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1041])
Data error at batch 2031: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 144.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 898])
Data error at batch 2032: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 206.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 898])
Data error at batch 2033: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 206.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 890])
Data error at batch 2034: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 211.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 890])
Data error at batch 2035: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 211.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 899])
Data error at batch 2036: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 206.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 899])
Data error at batch 2037: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 206.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 883])
Data error at batch 2038: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 216.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 883])
Data error at batch 2039: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 216.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1234])
Data error at batch 2040: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1234])
Data error at batch 2041: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1237])
Data error at batch 2042: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1237])
Data error at batch 2043: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1282])
Data error at batch 2044: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 114.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1282])
Data error at batch 2045: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 117.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1231])
Data error at batch 2046: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1231])
Data error at batch 2047: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 849])
Data error at batch 2048: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 116.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 849])
Data error at batch 2049: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 116.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 870])
Data error at batch 2050: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 870])
Data error at batch 2051: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 125.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 872])
Data error at batch 2052: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 123.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 872])
Data error at batch 2053: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 123.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 848])
Data error at batch 2054: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 848])
Data error at batch 2055: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1749])
Data error at batch 2056: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1749])
Data error at batch 2057: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1765])
Data error at batch 2058: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1765])
Data error at batch 2059: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1782])
Data error at batch 2060: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1782])
Data error at batch 2061: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1758])
Data error at batch 2062: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1758])
Data error at batch 2063: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 990])
Data error at batch 2064: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 172.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 990])
Data error at batch 2065: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 172.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 987])
Data error at batch 2066: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 176.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 987])
Data error at batch 2067: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 176.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1025])
Data error at batch 2068: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 151.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1025])
Data error at batch 2069: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 151.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 982])
Data error at batch 2070: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 179.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 982])
Data error at batch 2071: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 179.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1041])
Data error at batch 2072: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 164.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1041])
Data error at batch 2073: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 164.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1042])
Data error at batch 2074: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 163.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1042])
Data error at batch 2075: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 163.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1059])
Data error at batch 2076: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 173.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1059])
Data error at batch 2077: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 173.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1015])
Data error at batch 2078: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 156.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1015])
Data error at batch 2079: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 156.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1598])
Data error at batch 2080: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1598])
Data error at batch 2081: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1619])
Data error at batch 2082: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1619])
Data error at batch 2083: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1631])
Data error at batch 2084: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 119.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1631])
Data error at batch 2085: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 119.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1585])
Data error at batch 2086: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 142.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1585])
Data error at batch 2087: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 142.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1912])
Data error at batch 2088: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 93.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1912])
Data error at batch 2089: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 104.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1954])
Data error at batch 2090: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 168.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1954])
Data error at batch 2091: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 160.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1935])
Data error at batch 2092: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 184.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1935])
Data error at batch 2093: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 184.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1921])
Data error at batch 2094: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1921])
Data error at batch 2095: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 854])
Data error at batch 2096: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 854])
Data error at batch 2097: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 897])
Data error at batch 2098: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 897])
Data error at batch 2099: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 876])
Data error at batch 2100: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 876])
Data error at batch 2101: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 857])
Data error at batch 2102: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 857])
Data error at batch 2103: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1331])
Data error at batch 2104: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 169.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1331])
Data error at batch 2105: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 169.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1330])
Data error at batch 2106: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 167.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1330])
Data error at batch 2107: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 167.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1337])
Data error at batch 2108: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 167.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1337])
Data error at batch 2109: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 167.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1318])
Data error at batch 2110: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 104.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1318])
Data error at batch 2111: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 104.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1016])
Data error at batch 2112: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1016])
Data error at batch 2113: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 993])
Data error at batch 2114: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 993])
Data error at batch 2115: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1023])
Data error at batch 2116: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1023])
Data error at batch 2117: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 990])
Data error at batch 2118: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 73.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 990])
Data error at batch 2119: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 73.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1283])
Data error at batch 2120: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1283])
Data error at batch 2121: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1290])
Data error at batch 2122: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1290])
Data error at batch 2123: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1303])
Data error at batch 2124: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 118.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1303])
Data error at batch 2125: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 118.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1272])
Data error at batch 2126: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 114.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1272])
Data error at batch 2127: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 114.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 929])
Data error at batch 2128: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 79.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 929])
Data error at batch 2129: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 79.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 945])
Data error at batch 2130: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 70.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 945])
Data error at batch 2131: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 70.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 940])
Data error at batch 2132: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 73.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 940])
Data error at batch 2133: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 73.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 902])
Data error at batch 2134: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 85.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 902])
Data error at batch 2135: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 85.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1487])
Data error at batch 2136: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 235.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1487])
Data error at batch 2137: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 235.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1482])
Data error at batch 2138: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 240.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1482])
Data error at batch 2139: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 240.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1503])
Data error at batch 2140: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 229.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1503])
Data error at batch 2141: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 229.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1465])
Data error at batch 2142: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 246.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1465])
Data error at batch 2143: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 246.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1131])
Data error at batch 2144: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 102.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1131])
Data error at batch 2145: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 102.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1149])
Data error at batch 2146: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1149])
Data error at batch 2147: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1162])
Data error at batch 2148: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 135.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1162])
Data error at batch 2149: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 135.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1139])
Data error at batch 2150: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1139])
Data error at batch 2151: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1215])
Data error at batch 2152: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1215])
Data error at batch 2153: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1202])
Data error at batch 2154: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 155.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1202])
Data error at batch 2155: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 155.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1232])
Data error at batch 2156: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 138.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1232])
Data error at batch 2157: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 138.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1189])
Data error at batch 2158: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1189])
Data error at batch 2159: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1021])
Data error at batch 2160: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1021])
Data error at batch 2161: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1019])
Data error at batch 2162: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1019])
Data error at batch 2163: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1017])
Data error at batch 2164: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1017])
Data error at batch 2165: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1001])
Data error at batch 2166: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1001])
Data error at batch 2167: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1373])
Data error at batch 2168: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 234.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1373])
Data error at batch 2169: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 234.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1402])
Data error at batch 2170: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 222.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1402])
Data error at batch 2171: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 222.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1401])
Data error at batch 2172: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 222.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1401])
Data error at batch 2173: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 222.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1369])
Data error at batch 2174: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 236.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1369])
Data error at batch 2175: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 236.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1312])
Data error at batch 2176: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 105.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1312])
Data error at batch 2177: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 105.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1318])
Data error at batch 2178: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 104.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1318])
Data error at batch 2179: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 104.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1309])
Data error at batch 2180: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 115.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1309])
Data error at batch 2181: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 115.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1283])
Data error at batch 2182: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1283])
Data error at batch 2183: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1305])
Data error at batch 2184: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 117.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1305])
Data error at batch 2185: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 117.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1283])
Data error at batch 2186: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1283])
Data error at batch 2187: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1318])
Data error at batch 2188: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 104.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1318])
Data error at batch 2189: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 104.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1291])
Data error at batch 2190: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 123.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1291])
Data error at batch 2191: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 123.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2057])
Data error at batch 2192: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 115.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2057])
Data error at batch 2193: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 115.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2056])
Data error at batch 2194: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 115.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2056])
Data error at batch 2195: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 115.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2105])
Data error at batch 2196: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 92.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2105])
Data error at batch 2197: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 92.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2054])
Data error at batch 2198: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 109.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2054])
Data error at batch 2199: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 109.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 988])
Data error at batch 2200: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 988])
Data error at batch 2201: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 122.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 979])
Data error at batch 2202: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 979])
Data error at batch 2203: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1007])
Data error at batch 2204: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 110.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1007])
Data error at batch 2205: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 110.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 967])
Data error at batch 2206: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 87.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 967])
Data error at batch 2207: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 87.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1211])
Data error at batch 2208: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1211])
Data error at batch 2209: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1238])
Data error at batch 2210: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 126.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1238])
Data error at batch 2211: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 126.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1252])
Data error at batch 2212: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1252])
Data error at batch 2213: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 121.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1209])
Data error at batch 2214: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 144.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1209])
Data error at batch 2215: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 144.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 812])
Data error at batch 2216: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 812])
Data error at batch 2217: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 844])
Data error at batch 2218: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 844])
Data error at batch 2219: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 840])
Data error at batch 2220: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 840])
Data error at batch 2221: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 829])
Data error at batch 2222: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 829])
Data error at batch 2223: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 751])
Data error at batch 2224: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 751])
Data error at batch 2225: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 746])
Data error at batch 2226: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 746])
Data error at batch 2227: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 751])
Data error at batch 2228: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 751])
Data error at batch 2229: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 732])
Data error at batch 2230: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 732])
Data error at batch 2231: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 965])
Data error at batch 2232: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 965])
Data error at batch 2233: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1003])
Data error at batch 2234: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 113.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1003])
Data error at batch 2235: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 113.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1024])
Data error at batch 2236: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 96.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1024])
Data error at batch 2237: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 96.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 997])
Data error at batch 2238: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 117.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 997])
Data error at batch 2239: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 117.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1578])
Data error at batch 2240: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 204.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1578])
Data error at batch 2241: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 229.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1555])
Data error at batch 2242: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 241.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1555])
Data error at batch 2243: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 241.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1589])
Data error at batch 2244: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 226.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1589])
Data error at batch 2245: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 226.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1542])
Data error at batch 2246: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 246.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1542])
Data error at batch 2247: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 246.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1661])
Data error at batch 2248: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 199.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1661])
Data error at batch 2249: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 199.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1637])
Data error at batch 2250: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 210.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1637])
Data error at batch 2251: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 210.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1674])
Data error at batch 2252: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 194.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1674])
Data error at batch 2253: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 194.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1626])
Data error at batch 2254: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 214.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1626])
Data error at batch 2255: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 214.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2169])
Data error at batch 2256: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 66.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2169])
Data error at batch 2257: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 66.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2176])
Data error at batch 2258: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 66.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2176])
Data error at batch 2259: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 66.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2192])
Data error at batch 2260: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 171.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2192])
Data error at batch 2261: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 171.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2161])
Data error at batch 2262: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 88.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2161])
Data error at batch 2263: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 88.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1786])
Data error at batch 2264: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 217.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1786])
Data error at batch 2265: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 217.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1786])
Data error at batch 2266: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 217.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1786])
Data error at batch 2267: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 217.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1808])
Data error at batch 2268: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 209.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1808])
Data error at batch 2269: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 209.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1776])
Data error at batch 2270: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 220.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1776])
Data error at batch 2271: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 220.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 798])
Data error at batch 2272: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 798])
Data error at batch 2273: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 832])
Data error at batch 2274: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 832])
Data error at batch 2275: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 820])
Data error at batch 2276: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 820])
Data error at batch 2277: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 800])
Data error at batch 2278: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 800])
Data error at batch 2279: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 988])
Data error at batch 2280: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 988])
Data error at batch 2281: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1020])
Data error at batch 2282: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 104.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1020])
Data error at batch 2283: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 104.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1022])
Data error at batch 2284: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 103.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1022])
Data error at batch 2285: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 103.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 970])
Data error at batch 2286: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 970])
Data error at batch 2287: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 839])
Data error at batch 2288: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 81.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 839])
Data error at batch 2289: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 81.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 861])
Data error at batch 2290: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 63.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 861])
Data error at batch 2291: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 63.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 889])
Data error at batch 2292: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 63.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 889])
Data error at batch 2293: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 63.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 852])
Data error at batch 2294: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 852])
Data error at batch 2295: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 608])
Data error at batch 2296: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 22.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 608])
Data error at batch 2297: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 22.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 602])
Data error at batch 2298: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 31.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 602])
Data error at batch 2299: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 31.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 604])
Data error at batch 2300: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 28.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 604])
Data error at batch 2301: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 28.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 579])
Data error at batch 2302: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 36.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 579])
Data error at batch 2303: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 36.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1156])
Data error at batch 2304: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 120.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1156])
Data error at batch 2305: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 121.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1177])
Data error at batch 2306: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 111.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1177])
Data error at batch 2307: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 111.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1200])
Data error at batch 2308: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 125.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1200])
Data error at batch 2309: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 116.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1177])
Data error at batch 2310: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 97.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1177])
Data error at batch 2311: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 97.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1346])
Data error at batch 2312: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 99.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1346])
Data error at batch 2313: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1382])
Data error at batch 2314: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1382])
Data error at batch 2315: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1380])
Data error at batch 2316: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1380])
Data error at batch 2317: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1346])
Data error at batch 2318: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1346])
Data error at batch 2319: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 773])
Data error at batch 2320: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 111.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 773])
Data error at batch 2321: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 111.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 757])
Data error at batch 2322: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 93.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 757])
Data error at batch 2323: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 93.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 781])
Data error at batch 2324: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 781])
Data error at batch 2325: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 750])
Data error at batch 2326: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 750])
Data error at batch 2327: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1320])
Data error at batch 2328: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 108.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1320])
Data error at batch 2329: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 110.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1347])
Data error at batch 2330: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 63.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1347])
Data error at batch 2331: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 85.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1380])
Data error at batch 2332: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 74.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1380])
Data error at batch 2333: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 74.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1315])
Data error at batch 2334: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 118.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1315])
Data error at batch 2335: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 118.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 956])
Data error at batch 2336: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 150.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 956])
Data error at batch 2337: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 150.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 956])
Data error at batch 2338: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 150.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 956])
Data error at batch 2339: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 150.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 969])
Data error at batch 2340: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 210.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 969])
Data error at batch 2341: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 210.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 938])
Data error at batch 2342: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 73.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 938])
Data error at batch 2343: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 73.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 404])
Data error at batch 2344: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 32.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 404])
Data error at batch 2345: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 32.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 395])
Data error at batch 2346: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.96 GiB is allocated by PyTorch, and 20.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 395])
Data error at batch 2347: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.96 GiB is allocated by PyTorch, and 20.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 455])
Data error at batch 2348: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 30.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 455])
Data error at batch 2349: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 30.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 407])
Data error at batch 2350: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 28.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 407])
Data error at batch 2351: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 28.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1883])
Data error at batch 2352: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 62.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1883])
Data error at batch 2353: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 20.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1916])
Data error at batch 2354: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 71.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1916])
Data error at batch 2355: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 71.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1932])
Data error at batch 2356: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 179.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1932])
Data error at batch 2357: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 149.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1891])
Data error at batch 2358: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 95.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1891])
Data error at batch 2359: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 125.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1073])
Data error at batch 2360: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1073])
Data error at batch 2361: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1096])
Data error at batch 2362: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 123.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1096])
Data error at batch 2363: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 123.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1105])
Data error at batch 2364: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 118.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1105])
Data error at batch 2365: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 118.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1064])
Data error at batch 2366: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1064])
Data error at batch 2367: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1597])
Data error at batch 2368: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 212.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1597])
Data error at batch 2369: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 212.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1614])
Data error at batch 2370: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 206.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1614])
Data error at batch 2371: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 206.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1650])
Data error at batch 2372: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 189.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1650])
Data error at batch 2373: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 189.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1607])
Data error at batch 2374: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 208.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1607])
Data error at batch 2375: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 208.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1814])
Data error at batch 2376: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 155.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1814])
Data error at batch 2377: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 155.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1832])
Data error at batch 2378: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1832])
Data error at batch 2379: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1821])
Data error at batch 2380: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 153.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1821])
Data error at batch 2381: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 153.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1799])
Data error at batch 2382: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1799])
Data error at batch 2383: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1706])
Data error at batch 2384: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 170.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1706])
Data error at batch 2385: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 170.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1714])
Data error at batch 2386: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 167.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1714])
Data error at batch 2387: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 167.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1708])
Data error at batch 2388: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 169.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1708])
Data error at batch 2389: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 169.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1678])
Data error at batch 2390: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 180.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1678])
Data error at batch 2391: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 180.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 918])
Data error at batch 2392: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 87.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 918])
Data error at batch 2393: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 87.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 930])
Data error at batch 2394: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 930])
Data error at batch 2395: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 919])
Data error at batch 2396: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 919])
Data error at batch 2397: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 894])
Data error at batch 2398: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 894])
Data error at batch 2399: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 814])
Data error at batch 2400: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 814])
Data error at batch 2401: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 827])
Data error at batch 2402: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 827])
Data error at batch 2403: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 835])
Data error at batch 2404: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 79.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 835])
Data error at batch 2405: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 79.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 798])
Data error at batch 2406: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 798])
Data error at batch 2407: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1062])
Data error at batch 2408: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1062])
Data error at batch 2409: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1094])
Data error at batch 2410: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 124.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1094])
Data error at batch 2411: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 124.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1139])
Data error at batch 2412: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 92.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1139])
Data error at batch 2413: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 92.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1081])
Data error at batch 2414: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1081])
Data error at batch 2415: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 859])
Data error at batch 2416: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 859])
Data error at batch 2417: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 853])
Data error at batch 2418: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 853])
Data error at batch 2419: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 887])
Data error at batch 2420: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 887])
Data error at batch 2421: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 845])
Data error at batch 2422: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 845])
Data error at batch 2423: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 760])
Data error at batch 2424: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 760])
Data error at batch 2425: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 796])
Data error at batch 2426: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 796])
Data error at batch 2427: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 798])
Data error at batch 2428: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 798])
Data error at batch 2429: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 764])
Data error at batch 2430: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 69.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 764])
Data error at batch 2431: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 69.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1752])
Data error at batch 2432: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1752])
Data error at batch 2433: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1740])
Data error at batch 2434: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 156.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1740])
Data error at batch 2435: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 156.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1812])
Data error at batch 2436: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 156.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1812])
Data error at batch 2437: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 156.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1737])
Data error at batch 2438: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1737])
Data error at batch 2439: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 939])
Data error at batch 2440: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 939])
Data error at batch 2441: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 959])
Data error at batch 2442: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 959])
Data error at batch 2443: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 989])
Data error at batch 2444: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 70.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 989])
Data error at batch 2445: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 70.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 944])
Data error at batch 2446: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 944])
Data error at batch 2447: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1202])
Data error at batch 2448: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1202])
Data error at batch 2449: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1204])
Data error at batch 2450: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1204])
Data error at batch 2451: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1220])
Data error at batch 2452: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1220])
Data error at batch 2453: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1189])
Data error at batch 2454: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 157.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1189])
Data error at batch 2455: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 157.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1169])
Data error at batch 2456: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 167.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1169])
Data error at batch 2457: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 167.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1165])
Data error at batch 2458: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 168.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1165])
Data error at batch 2459: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 168.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1204])
Data error at batch 2460: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1204])
Data error at batch 2461: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1159])
Data error at batch 2462: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 172.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1159])
Data error at batch 2463: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 172.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1097])
Data error at batch 2464: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 123.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1097])
Data error at batch 2465: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 123.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1117])
Data error at batch 2466: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 111.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1117])
Data error at batch 2467: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 111.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1103])
Data error at batch 2468: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 119.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1103])
Data error at batch 2469: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 119.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1079])
Data error at batch 2470: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 131.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1079])
Data error at batch 2471: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 131.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1781])
Data error at batch 2472: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1781])
Data error at batch 2473: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1802])
Data error at batch 2474: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 160.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1802])
Data error at batch 2475: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 160.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1817])
Data error at batch 2476: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 154.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1817])
Data error at batch 2477: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 154.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1770])
Data error at batch 2478: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 143.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1770])
Data error at batch 2479: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 143.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1972])
Data error at batch 2480: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 132.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1972])
Data error at batch 2481: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 144.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2016])
Data error at batch 2482: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 69.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2016])
Data error at batch 2483: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 140.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2019])
Data error at batch 2484: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 140.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2019])
Data error at batch 2485: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 140.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2002])
Data error at batch 2486: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 143.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2002])
Data error at batch 2487: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 143.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1681])
Data error at batch 2488: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 173.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1681])
Data error at batch 2489: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 173.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1684])
Data error at batch 2490: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 172.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1684])
Data error at batch 2491: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 172.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1703])
Data error at batch 2492: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 165.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1703])
Data error at batch 2493: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 165.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1646])
Data error at batch 2494: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 187.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1646])
Data error at batch 2495: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 187.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2136])
Data error at batch 2496: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 152.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2136])
Data error at batch 2497: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 153.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2161])
Data error at batch 2498: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 144.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2161])
Data error at batch 2499: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 144.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2171])
Data error at batch 2500: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 142.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2171])
Data error at batch 2501: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 142.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2166])
Data error at batch 2502: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 143.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2166])
Data error at batch 2503: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 143.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 700])
Data error at batch 2504: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 700])
Data error at batch 2505: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 686])
Data error at batch 2506: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 686])
Data error at batch 2507: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 711])
Data error at batch 2508: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 711])
Data error at batch 2509: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 684])
Data error at batch 2510: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 684])
Data error at batch 2511: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2712])
Data error at batch 2512: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 41.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 97.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2712])
Data error at batch 2513: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 76.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2718])
Data error at batch 2514: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 72.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2718])
Data error at batch 2515: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 72.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2765])
Data error at batch 2516: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 85.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2765])
Data error at batch 2517: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 85.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2711])
Data error at batch 2518: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 105.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2711])
Data error at batch 2519: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 105.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1248])
Data error at batch 2520: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 116.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1248])
Data error at batch 2521: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 116.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1252])
Data error at batch 2522: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 115.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1252])
Data error at batch 2523: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 115.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1295])
Data error at batch 2524: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 180.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1295])
Data error at batch 2525: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 180.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1231])
Data error at batch 2526: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1231])
Data error at batch 2527: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 790])
Data error at batch 2528: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 790])
Data error at batch 2529: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 823])
Data error at batch 2530: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 58.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 823])
Data error at batch 2531: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 58.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 840])
Data error at batch 2532: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 41.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 840])
Data error at batch 2533: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 41.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 805])
Data error at batch 2534: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 56.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 805])
Data error at batch 2535: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 56.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 931])
Data error at batch 2536: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 931])
Data error at batch 2537: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 958])
Data error at batch 2538: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 958])
Data error at batch 2539: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 973])
Data error at batch 2540: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 77.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 973])
Data error at batch 2541: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 77.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 932])
Data error at batch 2542: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 49.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 932])
Data error at batch 2543: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 49.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1214])
Data error at batch 2544: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 138.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1214])
Data error at batch 2545: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 138.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1250])
Data error at batch 2546: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 115.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1250])
Data error at batch 2547: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 115.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1245])
Data error at batch 2548: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 119.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1245])
Data error at batch 2549: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 119.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1196])
Data error at batch 2550: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 79.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1196])
Data error at batch 2551: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 79.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1432])
Data error at batch 2552: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1432])
Data error at batch 2553: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 179.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1436])
Data error at batch 2554: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 177.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1436])
Data error at batch 2555: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 177.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1443])
Data error at batch 2556: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 174.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1443])
Data error at batch 2557: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 174.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1411])
Data error at batch 2558: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1411])
Data error at batch 2559: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1148])
Data error at batch 2560: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1148])
Data error at batch 2561: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1145])
Data error at batch 2562: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 73.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1145])
Data error at batch 2563: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 73.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1189])
Data error at batch 2564: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1189])
Data error at batch 2565: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1150])
Data error at batch 2566: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 94.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1150])
Data error at batch 2567: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 94.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 796])
Data error at batch 2568: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 796])
Data error at batch 2569: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 817])
Data error at batch 2570: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 817])
Data error at batch 2571: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 853])
Data error at batch 2572: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 37.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 853])
Data error at batch 2573: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 37.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 798])
Data error at batch 2574: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 798])
Data error at batch 2575: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 565])
Data error at batch 2576: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 27.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 565])
Data error at batch 2577: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 27.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 578])
Data error at batch 2578: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 36.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 578])
Data error at batch 2579: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 36.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 573])
Data error at batch 2580: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 35.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 573])
Data error at batch 2581: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 35.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 565])
Data error at batch 2582: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 27.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 565])
Data error at batch 2583: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 27.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1158])
Data error at batch 2584: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1158])
Data error at batch 2585: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1148])
Data error at batch 2586: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1148])
Data error at batch 2587: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1184])
Data error at batch 2588: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 69.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1184])
Data error at batch 2589: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 69.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1138])
Data error at batch 2590: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1138])
Data error at batch 2591: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1425])
Data error at batch 2592: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1425])
Data error at batch 2593: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1442])
Data error at batch 2594: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 175.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1442])
Data error at batch 2595: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 175.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1466])
Data error at batch 2596: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 162.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1466])
Data error at batch 2597: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 162.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1410])
Data error at batch 2598: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1410])
Data error at batch 2599: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1461])
Data error at batch 2600: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 164.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1461])
Data error at batch 2601: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 164.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1474])
Data error at batch 2602: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 159.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1474])
Data error at batch 2603: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 159.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1478])
Data error at batch 2604: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1478])
Data error at batch 2605: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1477])
Data error at batch 2606: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1477])
Data error at batch 2607: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1487])
Data error at batch 2608: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1487])
Data error at batch 2609: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1487])
Data error at batch 2610: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1487])
Data error at batch 2611: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1476])
Data error at batch 2612: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 159.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1476])
Data error at batch 2613: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 159.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1451])
Data error at batch 2614: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 170.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1451])
Data error at batch 2615: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 170.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1078])
Data error at batch 2616: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 117.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1078])
Data error at batch 2617: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 117.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1082])
Data error at batch 2618: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 115.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1082])
Data error at batch 2619: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 115.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1093])
Data error at batch 2620: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1093])
Data error at batch 2621: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1072])
Data error at batch 2622: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 120.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1072])
Data error at batch 2623: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 120.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1240])
Data error at batch 2624: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1240])
Data error at batch 2625: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1255])
Data error at batch 2626: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 81.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1255])
Data error at batch 2627: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 81.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1262])
Data error at batch 2628: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 73.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1262])
Data error at batch 2629: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 73.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1237])
Data error at batch 2630: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 91.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1237])
Data error at batch 2631: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 91.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2153])
Data error at batch 2632: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 247.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2153])
Data error at batch 2633: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 247.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2202])
Data error at batch 2634: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 232.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2202])
Data error at batch 2635: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 232.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2185])
Data error at batch 2636: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 238.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2185])
Data error at batch 2637: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 238.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2155])
Data error at batch 2638: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 247.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2155])
Data error at batch 2639: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 247.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1125])
Data error at batch 2640: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1125])
Data error at batch 2641: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1121])
Data error at batch 2642: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1121])
Data error at batch 2643: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1178])
Data error at batch 2644: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1178])
Data error at batch 2645: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1119])
Data error at batch 2646: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 91.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1119])
Data error at batch 2647: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 91.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 836])
Data error at batch 2648: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 836])
Data error at batch 2649: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 817])
Data error at batch 2650: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 817])
Data error at batch 2651: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 832])
Data error at batch 2652: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 832])
Data error at batch 2653: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 810])
Data error at batch 2654: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 62.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 810])
Data error at batch 2655: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 62.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 978])
Data error at batch 2656: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 978])
Data error at batch 2657: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1012])
Data error at batch 2658: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1012])
Data error at batch 2659: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1022])
Data error at batch 2660: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1022])
Data error at batch 2661: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 962])
Data error at batch 2662: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 962])
Data error at batch 2663: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1074])
Data error at batch 2664: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 119.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1074])
Data error at batch 2665: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 119.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1111])
Data error at batch 2666: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 95.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1111])
Data error at batch 2667: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 95.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1096])
Data error at batch 2668: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 107.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1096])
Data error at batch 2669: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 107.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1104])
Data error at batch 2670: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 99.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1104])
Data error at batch 2671: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 99.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1057])
Data error at batch 2672: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 133.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1057])
Data error at batch 2673: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 133.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1096])
Data error at batch 2674: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 107.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1096])
Data error at batch 2675: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 107.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1107])
Data error at batch 2676: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 97.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1107])
Data error at batch 2677: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 97.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1068])
Data error at batch 2678: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 122.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1068])
Data error at batch 2679: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 122.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 974])
Data error at batch 2680: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 974])
Data error at batch 2681: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 955])
Data error at batch 2682: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 61.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 955])
Data error at batch 2683: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 61.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 974])
Data error at batch 2684: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 974])
Data error at batch 2685: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 950])
Data error at batch 2686: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 950])
Data error at batch 2687: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1399])
Data error at batch 2688: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 135.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1399])
Data error at batch 2689: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 135.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1394])
Data error at batch 2690: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 137.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1394])
Data error at batch 2691: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 137.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1408])
Data error at batch 2692: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1408])
Data error at batch 2693: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1393])
Data error at batch 2694: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 137.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1393])
Data error at batch 2695: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 137.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1026])
Data error at batch 2696: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1026])
Data error at batch 2697: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1016])
Data error at batch 2698: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1016])
Data error at batch 2699: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1030])
Data error at batch 2700: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1030])
Data error at batch 2701: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 996])
Data error at batch 2702: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 70.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 996])
Data error at batch 2703: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 70.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1365])
Data error at batch 2704: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 155.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1365])
Data error at batch 2705: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 155.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1374])
Data error at batch 2706: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1374])
Data error at batch 2707: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1380])
Data error at batch 2708: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1380])
Data error at batch 2709: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1330])
Data error at batch 2710: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 120.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1330])
Data error at batch 2711: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 120.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1576])
Data error at batch 2712: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 145.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1576])
Data error at batch 2713: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 145.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1605])
Data error at batch 2714: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 135.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1605])
Data error at batch 2715: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 135.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1619])
Data error at batch 2716: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 128.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1619])
Data error at batch 2717: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 128.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1592])
Data error at batch 2718: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1592])
Data error at batch 2719: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1297])
Data error at batch 2720: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1297])
Data error at batch 2721: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 143.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1323])
Data error at batch 2722: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 124.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1323])
Data error at batch 2723: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 124.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1317])
Data error at batch 2724: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1317])
Data error at batch 2725: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1286])
Data error at batch 2726: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 146.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1286])
Data error at batch 2727: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 146.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1800])
Data error at batch 2728: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 167.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1800])
Data error at batch 2729: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 167.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1806])
Data error at batch 2730: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 164.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1806])
Data error at batch 2731: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 164.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1864])
Data error at batch 2732: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 141.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1864])
Data error at batch 2733: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 141.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1803])
Data error at batch 2734: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 165.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1803])
Data error at batch 2735: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 165.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2160])
Data error at batch 2736: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 245.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2160])
Data error at batch 2737: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 245.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2190])
Data error at batch 2738: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 237.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2190])
Data error at batch 2739: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 237.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2176])
Data error at batch 2740: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 241.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2176])
Data error at batch 2741: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 241.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2151])
Data error at batch 2742: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 248.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2151])
Data error at batch 2743: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 248.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2058])
Data error at batch 2744: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.71 GiB is allocated by PyTorch, and 241.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2058])
Data error at batch 2745: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.71 GiB is allocated by PyTorch, and 241.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2037])
Data error at batch 2746: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 206.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2037])
Data error at batch 2747: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 206.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2073])
Data error at batch 2748: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 238.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2073])
Data error at batch 2749: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 238.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2035])
Data error at batch 2750: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 206.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2035])
Data error at batch 2751: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 206.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1067])
Data error at batch 2752: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 117.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1067])
Data error at batch 2753: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 116.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1075])
Data error at batch 2754: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 113.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1075])
Data error at batch 2755: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 113.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1090])
Data error at batch 2756: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 105.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1090])
Data error at batch 2757: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 105.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1065])
Data error at batch 2758: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 117.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1065])
Data error at batch 2759: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 117.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1176])
Data error at batch 2760: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1176])
Data error at batch 2761: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1180])
Data error at batch 2762: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1180])
Data error at batch 2763: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1208])
Data error at batch 2764: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 145.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1208])
Data error at batch 2765: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 145.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1168])
Data error at batch 2766: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1168])
Data error at batch 2767: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 762])
Data error at batch 2768: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 34.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 762])
Data error at batch 2769: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 34.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 799])
Data error at batch 2770: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 799])
Data error at batch 2771: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 787])
Data error at batch 2772: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 787])
Data error at batch 2773: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 765])
Data error at batch 2774: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 765])
Data error at batch 2775: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 677])
Data error at batch 2776: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 42.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 677])
Data error at batch 2777: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 42.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 709])
Data error at batch 2778: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 709])
Data error at batch 2779: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 705])
Data error at batch 2780: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 60.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 705])
Data error at batch 2781: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 60.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 693])
Data error at batch 2782: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 39.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 693])
Data error at batch 2783: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 39.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 890])
Data error at batch 2784: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 890])
Data error at batch 2785: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 912])
Data error at batch 2786: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 72.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 912])
Data error at batch 2787: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 72.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 927])
Data error at batch 2788: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 927])
Data error at batch 2789: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 893])
Data error at batch 2790: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 893])
Data error at batch 2791: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1295])
Data error at batch 2792: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 138.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1295])
Data error at batch 2793: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 138.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1296])
Data error at batch 2794: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 135.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1296])
Data error at batch 2795: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 135.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1290])
Data error at batch 2796: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 138.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1290])
Data error at batch 2797: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 138.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1262])
Data error at batch 2798: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 112.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1262])
Data error at batch 2799: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 112.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 631])
Data error at batch 2800: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 31.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 631])
Data error at batch 2801: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 31.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 626])
Data error at batch 2802: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 28.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 626])
Data error at batch 2803: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 28.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 644])
Data error at batch 2804: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 38.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 644])
Data error at batch 2805: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 38.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 616])
Data error at batch 2806: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 35.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 616])
Data error at batch 2807: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 35.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1943])
Data error at batch 2808: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 228.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1943])
Data error at batch 2809: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 228.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1960])
Data error at batch 2810: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 223.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1960])
Data error at batch 2811: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 223.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1997])
Data error at batch 2812: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 210.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1997])
Data error at batch 2813: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 210.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1946])
Data error at batch 2814: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 227.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1946])
Data error at batch 2815: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 227.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1323])
Data error at batch 2816: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 110.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1323])
Data error at batch 2817: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 110.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1351])
Data error at batch 2818: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 147.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1351])
Data error at batch 2819: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 147.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1357])
Data error at batch 2820: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 145.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1357])
Data error at batch 2821: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 145.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1323])
Data error at batch 2822: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 110.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1323])
Data error at batch 2823: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 110.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1073])
Data error at batch 2824: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 106.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1073])
Data error at batch 2825: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 106.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1058])
Data error at batch 2826: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 119.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1058])
Data error at batch 2827: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 119.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1080])
Data error at batch 2828: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 102.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1080])
Data error at batch 2829: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 102.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1043])
Data error at batch 2830: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1043])
Data error at batch 2831: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 932])
Data error at batch 2832: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 46.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 932])
Data error at batch 2833: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 46.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 941])
Data error at batch 2834: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 57.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 941])
Data error at batch 2835: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 57.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 951])
Data error at batch 2836: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 951])
Data error at batch 2837: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 901])
Data error at batch 2838: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 901])
Data error at batch 2839: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 656])
Data error at batch 2840: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 656])
Data error at batch 2841: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 35.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 661])
Data error at batch 2842: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 32.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 661])
Data error at batch 2843: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 32.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 692])
Data error at batch 2844: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 43.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 692])
Data error at batch 2845: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 43.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 661])
Data error at batch 2846: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 32.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 661])
Data error at batch 2847: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 32.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 920])
Data error at batch 2848: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 920])
Data error at batch 2849: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 937])
Data error at batch 2850: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 937])
Data error at batch 2851: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 945])
Data error at batch 2852: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 945])
Data error at batch 2853: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 907])
Data error at batch 2854: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 907])
Data error at batch 2855: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1486])
Data error at batch 2856: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 129.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1486])
Data error at batch 2857: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 129.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1498])
Data error at batch 2858: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 121.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1498])
Data error at batch 2859: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 121.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1514])
Data error at batch 2860: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 115.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1514])
Data error at batch 2861: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 115.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1475])
Data error at batch 2862: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 133.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1475])
Data error at batch 2863: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 133.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2375])
Data error at batch 2864: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 45.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.26 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 141.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2375])
Data error at batch 2865: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 134.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2394])
Data error at batch 2866: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 168.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2394])
Data error at batch 2867: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 149.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2409])
Data error at batch 2868: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 146.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2409])
Data error at batch 2869: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 146.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2346])
Data error at batch 2870: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 164.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2346])
Data error at batch 2871: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 33.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 164.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 811])
Data error at batch 2872: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 47.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 811])
Data error at batch 2873: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 48.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 835])
Data error at batch 2874: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 835])
Data error at batch 2875: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 39.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 861])
Data error at batch 2876: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 861])
Data error at batch 2877: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 823])
Data error at batch 2878: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 823])
Data error at batch 2879: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1612])
Data error at batch 2880: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1612])
Data error at batch 2881: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1665])
Data error at batch 2882: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 109.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1665])
Data error at batch 2883: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 111.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1670])
Data error at batch 2884: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 103.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1670])
Data error at batch 2885: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 103.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1618])
Data error at batch 2886: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 107.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1618])
Data error at batch 2887: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 107.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1222])
Data error at batch 2888: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 202.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1222])
Data error at batch 2889: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 202.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1211])
Data error at batch 2890: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 211.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1211])
Data error at batch 2891: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 211.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1264])
Data error at batch 2892: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 183.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1264])
Data error at batch 2893: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 183.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1212])
Data error at batch 2894: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 209.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1212])
Data error at batch 2895: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 209.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 679])
Data error at batch 2896: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 679])
Data error at batch 2897: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 711])
Data error at batch 2898: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 711])
Data error at batch 2899: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 723])
Data error at batch 2900: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 76.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 723])
Data error at batch 2901: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 76.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 682])
Data error at batch 2902: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 682])
Data error at batch 2903: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 625])
Data error at batch 2904: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 62.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 625])
Data error at batch 2905: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 62.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 612])
Data error at batch 2906: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 612])
Data error at batch 2907: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 623])
Data error at batch 2908: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 623])
Data error at batch 2909: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 597])
Data error at batch 2910: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 36.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 597])
Data error at batch 2911: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 36.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 874])
Data error at batch 2912: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 101.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 874])
Data error at batch 2913: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 101.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 898])
Data error at batch 2914: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 123.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 898])
Data error at batch 2915: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 123.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 887])
Data error at batch 2916: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 93.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 887])
Data error at batch 2917: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 93.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 842])
Data error at batch 2918: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 842])
Data error at batch 2919: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1417])
Data error at batch 2920: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 135.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1417])
Data error at batch 2921: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 165.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1406])
Data error at batch 2922: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 169.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1406])
Data error at batch 2923: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 169.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1445])
Data error at batch 2924: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 153.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1445])
Data error at batch 2925: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 153.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1394])
Data error at batch 2926: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 174.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1394])
Data error at batch 2927: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 174.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1386])
Data error at batch 2928: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 177.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1386])
Data error at batch 2929: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 177.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1420])
Data error at batch 2930: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 164.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1420])
Data error at batch 2931: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 164.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1447])
Data error at batch 2932: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 152.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1447])
Data error at batch 2933: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 152.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1420])
Data error at batch 2934: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 164.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1420])
Data error at batch 2935: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 164.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 839])
Data error at batch 2936: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 839])
Data error at batch 2937: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 874])
Data error at batch 2938: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 874])
Data error at batch 2939: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 874])
Data error at batch 2940: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 874])
Data error at batch 2941: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 830])
Data error at batch 2942: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 82.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 830])
Data error at batch 2943: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 82.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1244])
Data error at batch 2944: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 193.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1244])
Data error at batch 2945: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 193.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1263])
Data error at batch 2946: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 186.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1263])
Data error at batch 2947: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 186.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1265])
Data error at batch 2948: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 185.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1265])
Data error at batch 2949: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 185.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1272])
Data error at batch 2950: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 179.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1272])
Data error at batch 2951: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 179.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1928])
Data error at batch 2952: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 108.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1928])
Data error at batch 2953: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1943])
Data error at batch 2954: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 59.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1943])
Data error at batch 2955: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 89.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1972])
Data error at batch 2956: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 75.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1972])
Data error at batch 2957: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 75.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1930])
Data error at batch 2958: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 94.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1930])
Data error at batch 2959: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 94.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 761])
Data error at batch 2960: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 761])
Data error at batch 2961: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 792])
Data error at batch 2962: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 792])
Data error at batch 2963: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 71.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 788])
Data error at batch 2964: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 788])
Data error at batch 2965: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 764])
Data error at batch 2966: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 68.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 764])
Data error at batch 2967: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 68.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1437])
Data error at batch 2968: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 144.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1437])
Data error at batch 2969: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 145.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1462])
Data error at batch 2970: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 248.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1462])
Data error at batch 2971: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 248.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1461])
Data error at batch 2972: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 248.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1461])
Data error at batch 2973: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 248.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1428])
Data error at batch 2974: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1428])
Data error at batch 2975: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1622])
Data error at batch 2976: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 185.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1622])
Data error at batch 2977: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 185.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1615])
Data error at batch 2978: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 187.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1615])
Data error at batch 2979: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 187.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1630])
Data error at batch 2980: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 182.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1630])
Data error at batch 2981: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 182.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1596])
Data error at batch 2982: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 192.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1596])
Data error at batch 2983: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 192.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 803])
Data error at batch 2984: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 62.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 803])
Data error at batch 2985: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 820])
Data error at batch 2986: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 62.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 820])
Data error at batch 2987: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 62.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 823])
Data error at batch 2988: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 823])
Data error at batch 2989: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 780])
Data error at batch 2990: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 780])
Data error at batch 2991: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2210])
Data error at batch 2992: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 133.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2210])
Data error at batch 2993: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 133.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2265])
Data error at batch 2994: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 111.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2265])
Data error at batch 2995: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 111.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2270])
Data error at batch 2996: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 111.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2270])
Data error at batch 2997: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 111.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2212])
Data error at batch 2998: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 132.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2212])
Data error at batch 2999: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 132.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1043])
Data error at batch 3000: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1043])
Data error at batch 3001: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1087])
Data error at batch 3002: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 108.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1087])
Data error at batch 3003: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 108.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1086])
Data error at batch 3004: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1086])
Data error at batch 3005: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1050])
Data error at batch 3006: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 134.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1050])
Data error at batch 3007: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 134.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 533])
Data error at batch 3008: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 34.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 533])
Data error at batch 3009: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 34.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 586])
Data error at batch 3010: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 586])
Data error at batch 3011: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 577])
Data error at batch 3012: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 577])
Data error at batch 3013: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 529])
Data error at batch 3014: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 40.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 529])
Data error at batch 3015: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 40.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 809])
Data error at batch 3016: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 41.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 809])
Data error at batch 3017: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 41.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 848])
Data error at batch 3018: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 848])
Data error at batch 3019: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 870])
Data error at batch 3020: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 870])
Data error at batch 3021: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 804])
Data error at batch 3022: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 804])
Data error at batch 3023: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1537])
Data error at batch 3024: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 221.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1537])
Data error at batch 3025: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 245.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1578])
Data error at batch 3026: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 230.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1578])
Data error at batch 3027: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 230.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1590])
Data error at batch 3028: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 223.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1590])
Data error at batch 3029: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 223.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1544])
Data error at batch 3030: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 243.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1544])
Data error at batch 3031: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 243.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1364])
Data error at batch 3032: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 160.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1364])
Data error at batch 3033: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 160.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1363])
Data error at batch 3034: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 162.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1363])
Data error at batch 3035: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 162.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1381])
Data error at batch 3036: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 181.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1381])
Data error at batch 3037: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 181.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1356])
Data error at batch 3038: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 163.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1356])
Data error at batch 3039: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 163.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 945])
Data error at batch 3040: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 945])
Data error at batch 3041: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 969])
Data error at batch 3042: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 969])
Data error at batch 3043: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 68.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 989])
Data error at batch 3044: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 989])
Data error at batch 3045: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 82.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 943])
Data error at batch 3046: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 70.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 943])
Data error at batch 3047: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 70.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 964])
Data error at batch 3048: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 70.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 964])
Data error at batch 3049: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 70.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 980])
Data error at batch 3050: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 980])
Data error at batch 3051: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 974])
Data error at batch 3052: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 974])
Data error at batch 3053: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 934])
Data error at batch 3054: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 76.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 934])
Data error at batch 3055: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 76.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1405])
Data error at batch 3056: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 190.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1405])
Data error at batch 3057: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 190.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1391])
Data error at batch 3058: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 196.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1391])
Data error at batch 3059: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 196.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1440])
Data error at batch 3060: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 172.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1440])
Data error at batch 3061: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 172.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1375])
Data error at batch 3062: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 203.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1375])
Data error at batch 3063: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 203.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 669])
Data error at batch 3064: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 669])
Data error at batch 3065: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 668])
Data error at batch 3066: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 668])
Data error at batch 3067: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 58.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 676])
Data error at batch 3068: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 48.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 676])
Data error at batch 3069: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 48.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 669])
Data error at batch 3070: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 669])
Data error at batch 3071: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 56.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1498])
Data error at batch 3072: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 144.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1498])
Data error at batch 3073: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 144.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1498])
Data error at batch 3074: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 144.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1498])
Data error at batch 3075: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 144.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1529])
Data error at batch 3076: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 131.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1529])
Data error at batch 3077: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 131.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1466])
Data error at batch 3078: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1466])
Data error at batch 3079: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1163])
Data error at batch 3080: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 132.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1163])
Data error at batch 3081: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 132.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1192])
Data error at batch 3082: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 116.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1192])
Data error at batch 3083: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 116.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1192])
Data error at batch 3084: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 116.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1192])
Data error at batch 3085: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 116.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1162])
Data error at batch 3086: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 132.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1162])
Data error at batch 3087: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 132.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1064])
Data error at batch 3088: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1064])
Data error at batch 3089: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1040])
Data error at batch 3090: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 142.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1040])
Data error at batch 3091: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 142.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1070])
Data error at batch 3092: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 120.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1070])
Data error at batch 3093: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 120.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1035])
Data error at batch 3094: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 145.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1035])
Data error at batch 3095: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 145.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1080])
Data error at batch 3096: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 113.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1080])
Data error at batch 3097: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 113.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1097])
Data error at batch 3098: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 103.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1097])
Data error at batch 3099: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 103.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1106])
Data error at batch 3100: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1106])
Data error at batch 3101: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1071])
Data error at batch 3102: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 119.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1071])
Data error at batch 3103: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 119.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1014])
Data error at batch 3104: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 52.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1014])
Data error at batch 3105: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 52.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1024])
Data error at batch 3106: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1024])
Data error at batch 3107: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1015])
Data error at batch 3108: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1015])
Data error at batch 3109: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 978])
Data error at batch 3110: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 978])
Data error at batch 3111: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1123])
Data error at batch 3112: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 81.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1123])
Data error at batch 3113: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 81.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1158])
Data error at batch 3114: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1158])
Data error at batch 3115: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1170])
Data error at batch 3116: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1170])
Data error at batch 3117: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1138])
Data error at batch 3118: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1138])
Data error at batch 3119: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1823])
Data error at batch 3120: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 140.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1823])
Data error at batch 3121: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 204.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1818])
Data error at batch 3122: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 206.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1818])
Data error at batch 3123: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 206.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1846])
Data error at batch 3124: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 196.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1846])
Data error at batch 3125: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 196.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1805])
Data error at batch 3126: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 209.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1805])
Data error at batch 3127: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 209.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2572])
Data error at batch 3128: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 124.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2572])
Data error at batch 3129: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 124.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2622])
Data error at batch 3130: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 108.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2622])
Data error at batch 3131: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 108.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2622])
Data error at batch 3132: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 108.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2622])
Data error at batch 3133: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 108.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2592])
Data error at batch 3134: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 119.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2592])
Data error at batch 3135: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 119.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1549])
Data error at batch 3136: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 255.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1549])
Data error at batch 3137: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 255.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1542])
Data error at batch 3138: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 258.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1542])
Data error at batch 3139: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 258.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1590])
Data error at batch 3140: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 238.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1590])
Data error at batch 3141: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 238.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1531])
Data error at batch 3142: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 211.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1531])
Data error at batch 3143: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 211.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 675])
Data error at batch 3144: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 42.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 675])
Data error at batch 3145: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 42.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 696])
Data error at batch 3146: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 34.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 696])
Data error at batch 3147: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 34.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 683])
Data error at batch 3148: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 683])
Data error at batch 3149: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 651])
Data error at batch 3150: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 38.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 651])
Data error at batch 3151: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1424])
Data error at batch 3152: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 101.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1424])
Data error at batch 3153: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 101.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1458])
Data error at batch 3154: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 77.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1458])
Data error at batch 3155: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 77.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1473])
Data error at batch 3156: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 54.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1473])
Data error at batch 3157: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 54.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1436])
Data error at batch 3158: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 88.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1436])
Data error at batch 3159: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 88.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 816])
Data error at batch 3160: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 79.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 816])
Data error at batch 3161: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 805])
Data error at batch 3162: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 79.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 805])
Data error at batch 3163: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 79.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 815])
Data error at batch 3164: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 73.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 815])
Data error at batch 3165: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 73.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 803])
Data error at batch 3166: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 803])
Data error at batch 3167: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 888])
Data error at batch 3168: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 133.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 888])
Data error at batch 3169: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 133.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 873])
Data error at batch 3170: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 873])
Data error at batch 3171: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 109.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 898])
Data error at batch 3172: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 146.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 898])
Data error at batch 3173: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 146.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 868])
Data error at batch 3174: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 112.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 868])
Data error at batch 3175: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 112.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1316])
Data error at batch 3176: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 177.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1316])
Data error at batch 3177: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 177.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1294])
Data error at batch 3178: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1294])
Data error at batch 3179: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1347])
Data error at batch 3180: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 163.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1347])
Data error at batch 3181: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 163.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1294])
Data error at batch 3182: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1294])
Data error at batch 3183: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1333])
Data error at batch 3184: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 169.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1333])
Data error at batch 3185: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 169.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1345])
Data error at batch 3186: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 164.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1345])
Data error at batch 3187: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 164.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1373])
Data error at batch 3188: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1373])
Data error at batch 3189: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1340])
Data error at batch 3190: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 164.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1340])
Data error at batch 3191: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 164.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 687])
Data error at batch 3192: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 107.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 687])
Data error at batch 3193: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 107.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 716])
Data error at batch 3194: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 716])
Data error at batch 3195: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 730])
Data error at batch 3196: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 730])
Data error at batch 3197: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 72.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 689])
Data error at batch 3198: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 105.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 689])
Data error at batch 3199: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 105.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1381])
Data error at batch 3200: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 145.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1381])
Data error at batch 3201: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 145.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1387])
Data error at batch 3202: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 142.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1387])
Data error at batch 3203: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 142.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1406])
Data error at batch 3204: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 132.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1406])
Data error at batch 3205: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 132.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1366])
Data error at batch 3206: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1366])
Data error at batch 3207: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 752])
Data error at batch 3208: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 752])
Data error at batch 3209: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 762])
Data error at batch 3210: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 762])
Data error at batch 3211: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 804])
Data error at batch 3212: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 89.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 804])
Data error at batch 3213: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 83.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 764])
Data error at batch 3214: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 94.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 764])
Data error at batch 3215: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 94.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 657])
Data error at batch 3216: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 95.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 657])
Data error at batch 3217: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 95.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 632])
Data error at batch 3218: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 52.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 632])
Data error at batch 3219: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 52.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 675])
Data error at batch 3220: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 675])
Data error at batch 3221: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 649])
Data error at batch 3222: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 48.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 649])
Data error at batch 3223: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 48.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 537])
Data error at batch 3224: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 38.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 537])
Data error at batch 3225: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 38.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 567])
Data error at batch 3226: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 53.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 567])
Data error at batch 3227: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 53.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 551])
Data error at batch 3228: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 551])
Data error at batch 3229: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 526])
Data error at batch 3230: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 62.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 526])
Data error at batch 3231: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 62.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2272])
Data error at batch 3232: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 88.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2272])
Data error at batch 3233: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 63.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2293])
Data error at batch 3234: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 74.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2293])
Data error at batch 3235: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 39.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 74.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2313])
Data error at batch 3236: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 175.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2313])
Data error at batch 3237: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 175.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2263])
Data error at batch 3238: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 91.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2263])
Data error at batch 3239: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 91.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1721])
Data error at batch 3240: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 169.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1721])
Data error at batch 3241: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 176.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1731])
Data error at batch 3242: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 172.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1731])
Data error at batch 3243: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 172.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1757])
Data error at batch 3244: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 162.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1757])
Data error at batch 3245: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 162.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1708])
Data error at batch 3246: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 179.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1708])
Data error at batch 3247: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 179.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1813])
Data error at batch 3248: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 205.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1813])
Data error at batch 3249: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 205.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1819])
Data error at batch 3250: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 203.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1819])
Data error at batch 3251: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 203.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1834])
Data error at batch 3252: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 199.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1834])
Data error at batch 3253: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 199.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1774])
Data error at batch 3254: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 154.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1774])
Data error at batch 3255: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 154.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 709])
Data error at batch 3256: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 709])
Data error at batch 3257: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 32.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 726])
Data error at batch 3258: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 726])
Data error at batch 3259: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 754])
Data error at batch 3260: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 754])
Data error at batch 3261: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 50.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 723])
Data error at batch 3262: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 60.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 723])
Data error at batch 3263: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 60.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1869])
Data error at batch 3264: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 226.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1869])
Data error at batch 3265: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 226.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1872])
Data error at batch 3266: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 225.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1872])
Data error at batch 3267: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 225.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1893])
Data error at batch 3268: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 219.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1893])
Data error at batch 3269: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 219.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1849])
Data error at batch 3270: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 232.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1849])
Data error at batch 3271: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 232.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1187])
Data error at batch 3272: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 96.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1187])
Data error at batch 3273: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 70.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1212])
Data error at batch 3274: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1212])
Data error at batch 3275: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1217])
Data error at batch 3276: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 99.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1217])
Data error at batch 3277: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 99.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1166])
Data error at batch 3278: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 84.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1166])
Data error at batch 3279: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 84.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 870])
Data error at batch 3280: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 870])
Data error at batch 3281: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 895])
Data error at batch 3282: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 895])
Data error at batch 3283: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 902])
Data error at batch 3284: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 902])
Data error at batch 3285: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 869])
Data error at batch 3286: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 869])
Data error at batch 3287: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2034])
Data error at batch 3288: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 194.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2034])
Data error at batch 3289: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 194.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2031])
Data error at batch 3290: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 195.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2031])
Data error at batch 3291: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 195.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2068])
Data error at batch 3292: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 184.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2068])
Data error at batch 3293: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 184.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2025])
Data error at batch 3294: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 197.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2025])
Data error at batch 3295: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 197.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1393])
Data error at batch 3296: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 196.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1393])
Data error at batch 3297: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 196.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1440])
Data error at batch 3298: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 155.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1440])
Data error at batch 3299: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 155.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1425])
Data error at batch 3300: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 161.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1425])
Data error at batch 3301: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 161.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1380])
Data error at batch 3302: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 182.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1380])
Data error at batch 3303: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 182.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1085])
Data error at batch 3304: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 116.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1085])
Data error at batch 3305: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 116.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1092])
Data error at batch 3306: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 112.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1092])
Data error at batch 3307: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 112.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1121])
Data error at batch 3308: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 91.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1121])
Data error at batch 3309: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 91.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1095])
Data error at batch 3310: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 110.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1095])
Data error at batch 3311: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 110.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 755])
Data error at batch 3312: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 755])
Data error at batch 3313: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 781])
Data error at batch 3314: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 781])
Data error at batch 3315: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 785])
Data error at batch 3316: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 50.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 785])
Data error at batch 3317: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 50.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 763])
Data error at batch 3318: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 763])
Data error at batch 3319: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1018])
Data error at batch 3320: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1018])
Data error at batch 3321: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1011])
Data error at batch 3322: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1011])
Data error at batch 3323: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1028])
Data error at batch 3324: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 95.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1028])
Data error at batch 3325: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 95.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 987])
Data error at batch 3326: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 72.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 987])
Data error at batch 3327: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 72.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 735])
Data error at batch 3328: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 735])
Data error at batch 3329: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 758])
Data error at batch 3330: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 758])
Data error at batch 3331: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 779])
Data error at batch 3332: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 779])
Data error at batch 3333: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 716])
Data error at batch 3334: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 716])
Data error at batch 3335: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 777])
Data error at batch 3336: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 777])
Data error at batch 3337: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 788])
Data error at batch 3338: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 788])
Data error at batch 3339: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 772])
Data error at batch 3340: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 772])
Data error at batch 3341: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 60.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 755])
Data error at batch 3342: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 755])
Data error at batch 3343: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 53.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 644])
Data error at batch 3344: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 36.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 644])
Data error at batch 3345: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 36.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 683])
Data error at batch 3346: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 683])
Data error at batch 3347: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 678])
Data error at batch 3348: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 678])
Data error at batch 3349: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 661])
Data error at batch 3350: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 661])
Data error at batch 3351: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1521])
Data error at batch 3352: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 133.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1521])
Data error at batch 3353: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 133.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1524])
Data error at batch 3354: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 132.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1524])
Data error at batch 3355: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 132.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1543])
Data error at batch 3356: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1543])
Data error at batch 3357: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 158.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1495])
Data error at batch 3358: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 142.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1495])
Data error at batch 3359: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 142.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 536])
Data error at batch 3360: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 28.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 536])
Data error at batch 3361: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 28.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 528])
Data error at batch 3362: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 20.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 528])
Data error at batch 3363: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 20.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 565])
Data error at batch 3364: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 21.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 565])
Data error at batch 3365: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 21.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 559])
Data error at batch 3366: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 31.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 559])
Data error at batch 3367: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 31.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1566])
Data error at batch 3368: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1566])
Data error at batch 3369: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1567])
Data error at batch 3370: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1567])
Data error at batch 3371: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1607])
Data error at batch 3372: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 236.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1607])
Data error at batch 3373: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 236.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1577])
Data error at batch 3374: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 141.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1577])
Data error at batch 3375: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 141.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1029])
Data error at batch 3376: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1029])
Data error at batch 3377: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1062])
Data error at batch 3378: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 87.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1062])
Data error at batch 3379: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 87.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1056])
Data error at batch 3380: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1056])
Data error at batch 3381: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 90.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1030])
Data error at batch 3382: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1030])
Data error at batch 3383: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 917])
Data error at batch 3384: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 917])
Data error at batch 3385: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 900])
Data error at batch 3386: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 900])
Data error at batch 3387: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 917])
Data error at batch 3388: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 917])
Data error at batch 3389: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 65.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 886])
Data error at batch 3390: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 48.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 886])
Data error at batch 3391: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 48.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 649])
Data error at batch 3392: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 42.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 649])
Data error at batch 3393: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 42.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 640])
Data error at batch 3394: CUDA out of memory. Tried to allocate 10.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 19.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 640])
Data error at batch 3395: CUDA out of memory. Tried to allocate 10.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 19.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 667])
Data error at batch 3396: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 667])
Data error at batch 3397: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 634])
Data error at batch 3398: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 28.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 634])
Data error at batch 3399: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 28.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1463])
Data error at batch 3400: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1463])
Data error at batch 3401: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1448])
Data error at batch 3402: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 168.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1448])
Data error at batch 3403: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 168.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1476])
Data error at batch 3404: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 155.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1476])
Data error at batch 3405: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 155.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1475])
Data error at batch 3406: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 155.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1475])
Data error at batch 3407: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 155.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 699])
Data error at batch 3408: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 699])
Data error at batch 3409: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 716])
Data error at batch 3410: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 716])
Data error at batch 3411: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 746])
Data error at batch 3412: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 746])
Data error at batch 3413: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 708])
Data error at batch 3414: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 708])
Data error at batch 3415: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1361])
Data error at batch 3416: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 150.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1361])
Data error at batch 3417: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 150.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1386])
Data error at batch 3418: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 196.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1386])
Data error at batch 3419: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 196.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1398])
Data error at batch 3420: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 189.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1398])
Data error at batch 3421: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 189.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1349])
Data error at batch 3422: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 156.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1349])
Data error at batch 3423: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 156.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1439])
Data error at batch 3424: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 152.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1439])
Data error at batch 3425: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 152.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1450])
Data error at batch 3426: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 147.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1450])
Data error at batch 3427: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 147.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1461])
Data error at batch 3428: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 142.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1461])
Data error at batch 3429: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 142.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1451])
Data error at batch 3430: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 146.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1451])
Data error at batch 3431: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 146.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1713])
Data error at batch 3432: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 174.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1713])
Data error at batch 3433: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 174.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1721])
Data error at batch 3434: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 172.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1721])
Data error at batch 3435: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 172.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1744])
Data error at batch 3436: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 162.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1744])
Data error at batch 3437: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 162.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1720])
Data error at batch 3438: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 172.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1720])
Data error at batch 3439: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 172.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 796])
Data error at batch 3440: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 796])
Data error at batch 3441: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 826])
Data error at batch 3442: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 826])
Data error at batch 3443: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 59.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 840])
Data error at batch 3444: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 840])
Data error at batch 3445: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 809])
Data error at batch 3446: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 41.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 809])
Data error at batch 3447: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 41.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1631])
Data error at batch 3448: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 208.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1631])
Data error at batch 3449: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 25.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 208.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1642])
Data error at batch 3450: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 202.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1642])
Data error at batch 3451: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 61.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1645])
Data error at batch 3452: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 60.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1645])
Data error at batch 3453: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 60.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1621])
Data error at batch 3454: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 67.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1621])
Data error at batch 3455: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 67.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1198])
Data error at batch 3456: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 216.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1198])
Data error at batch 3457: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 216.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1222])
Data error at batch 3458: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 206.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1222])
Data error at batch 3459: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 206.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1246])
Data error at batch 3460: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 148.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1246])
Data error at batch 3461: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 167.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1196])
Data error at batch 3462: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 191.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1196])
Data error at batch 3463: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 191.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2148])
Data error at batch 3464: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 83.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2148])
Data error at batch 3465: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 63.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2159])
Data error at batch 3466: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 109.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2159])
Data error at batch 3467: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 109.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2208])
Data error at batch 3468: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 136.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2208])
Data error at batch 3469: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 110.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2171])
Data error at batch 3470: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 76.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2171])
Data error at batch 3471: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 76.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 539])
Data error at batch 3472: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 44.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 539])
Data error at batch 3473: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 69.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 566])
Data error at batch 3474: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 132.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 566])
Data error at batch 3475: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 132.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 576])
Data error at batch 3476: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 576])
Data error at batch 3477: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 547])
Data error at batch 3478: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 157.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 547])
Data error at batch 3479: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 157.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2104])
Data error at batch 3480: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 108.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2104])
Data error at batch 3481: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 88.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2086])
Data error at batch 3482: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 94.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2086])
Data error at batch 3483: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 94.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2132])
Data error at batch 3484: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 70.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2132])
Data error at batch 3485: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 70.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2089])
Data error at batch 3486: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 93.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2089])
Data error at batch 3487: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 93.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1315])
Data error at batch 3488: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 167.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1315])
Data error at batch 3489: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 168.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1340])
Data error at batch 3490: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 151.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1340])
Data error at batch 3491: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 151.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1366])
Data error at batch 3492: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 140.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1366])
Data error at batch 3493: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 140.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1294])
Data error at batch 3494: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 176.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1294])
Data error at batch 3495: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 176.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1173])
Data error at batch 3496: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 93.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1173])
Data error at batch 3497: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 93.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1179])
Data error at batch 3498: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1179])
Data error at batch 3499: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1177])
Data error at batch 3500: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 92.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1177])
Data error at batch 3501: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 92.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1150])
Data error at batch 3502: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 104.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1150])
Data error at batch 3503: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 104.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1081])
Data error at batch 3504: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 103.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1081])
Data error at batch 3505: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 103.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1117])
Data error at batch 3506: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 126.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1117])
Data error at batch 3507: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 126.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1108])
Data error at batch 3508: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 134.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1108])
Data error at batch 3509: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 134.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1057])
Data error at batch 3510: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 116.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1057])
Data error at batch 3511: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 116.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1515])
Data error at batch 3512: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 238.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1515])
Data error at batch 3513: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 238.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1541])
Data error at batch 3514: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 230.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1541])
Data error at batch 3515: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 230.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1548])
Data error at batch 3516: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 227.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1548])
Data error at batch 3517: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 227.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1517])
Data error at batch 3518: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 237.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1517])
Data error at batch 3519: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 237.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 916])
Data error at batch 3520: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 59.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 916])
Data error at batch 3521: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 59.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 902])
Data error at batch 3522: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 67.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 902])
Data error at batch 3523: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 67.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 912])
Data error at batch 3524: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 912])
Data error at batch 3525: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 882])
Data error at batch 3526: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 882])
Data error at batch 3527: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1161])
Data error at batch 3528: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 96.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1161])
Data error at batch 3529: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 96.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1180])
Data error at batch 3530: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 88.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1180])
Data error at batch 3531: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 88.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1203])
Data error at batch 3532: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 144.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1203])
Data error at batch 3533: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 144.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1163])
Data error at batch 3534: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 96.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1163])
Data error at batch 3535: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 96.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2161])
Data error at batch 3536: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 90.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2161])
Data error at batch 3537: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 90.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2205])
Data error at batch 3538: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 158.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2205])
Data error at batch 3539: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 139.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2223])
Data error at batch 3540: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 37.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 146.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2223])
Data error at batch 3541: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 37.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 146.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2196])
Data error at batch 3542: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 37.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 154.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2196])
Data error at batch 3543: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 37.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 154.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1185])
Data error at batch 3544: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 120.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1185])
Data error at batch 3545: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 110.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1191])
Data error at batch 3546: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 107.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1191])
Data error at batch 3547: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 107.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1217])
Data error at batch 3548: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 85.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1217])
Data error at batch 3549: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 85.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1193])
Data error at batch 3550: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 106.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1193])
Data error at batch 3551: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 106.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2568])
Data error at batch 3552: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 135.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2568])
Data error at batch 3553: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 135.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2541])
Data error at batch 3554: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 141.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2541])
Data error at batch 3555: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 141.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2570])
Data error at batch 3556: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 135.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2570])
Data error at batch 3557: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 135.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2557])
Data error at batch 3558: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 137.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2557])
Data error at batch 3559: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 137.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1195])
Data error at batch 3560: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1195])
Data error at batch 3561: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1208])
Data error at batch 3562: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1208])
Data error at batch 3563: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1197])
Data error at batch 3564: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1197])
Data error at batch 3565: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1184])
Data error at batch 3566: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1184])
Data error at batch 3567: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1720])
Data error at batch 3568: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 59.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1720])
Data error at batch 3569: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 59.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1724])
Data error at batch 3570: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 57.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1724])
Data error at batch 3571: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 57.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1736])
Data error at batch 3572: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 37.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1736])
Data error at batch 3573: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 37.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1714])
Data error at batch 3574: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 61.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1714])
Data error at batch 3575: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 61.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 949])
Data error at batch 3576: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 93.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 949])
Data error at batch 3577: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 95.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 952])
Data error at batch 3578: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 93.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 952])
Data error at batch 3579: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 93.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 978])
Data error at batch 3580: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 176.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 978])
Data error at batch 3581: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 176.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 955])
Data error at batch 3582: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 92.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 955])
Data error at batch 3583: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 92.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 811])
Data error at batch 3584: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 111.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 811])
Data error at batch 3585: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 111.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 843])
Data error at batch 3586: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 82.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 843])
Data error at batch 3587: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 82.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 824])
Data error at batch 3588: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 101.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 824])
Data error at batch 3589: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 101.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 833])
Data error at batch 3590: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 87.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 833])
Data error at batch 3591: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 87.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1811])
Data error at batch 3592: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 120.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1811])
Data error at batch 3593: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 130.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1800])
Data error at batch 3594: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 23.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 118.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1800])
Data error at batch 3595: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 94.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1851])
Data error at batch 3596: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 103.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1851])
Data error at batch 3597: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 103.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1790])
Data error at batch 3598: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 125.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1790])
Data error at batch 3599: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 125.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1280])
Data error at batch 3600: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 93.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1280])
Data error at batch 3601: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 93.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1278])
Data error at batch 3602: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 50.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1278])
Data error at batch 3603: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 50.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1321])
Data error at batch 3604: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 188.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1321])
Data error at batch 3605: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 188.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1248])
Data error at batch 3606: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 58.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1248])
Data error at batch 3607: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 58.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1803])
Data error at batch 3608: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 121.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1803])
Data error at batch 3609: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 121.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1819])
Data error at batch 3610: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 115.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1819])
Data error at batch 3611: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 115.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1806])
Data error at batch 3612: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 120.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1806])
Data error at batch 3613: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 120.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1789])
Data error at batch 3614: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 125.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1789])
Data error at batch 3615: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 125.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1629])
Data error at batch 3616: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 166.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1629])
Data error at batch 3617: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 166.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1621])
Data error at batch 3618: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 169.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1621])
Data error at batch 3619: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 169.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1654])
Data error at batch 3620: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 154.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1654])
Data error at batch 3621: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 154.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1613])
Data error at batch 3622: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 173.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1613])
Data error at batch 3623: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 173.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1492])
Data error at batch 3624: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 217.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1492])
Data error at batch 3625: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 217.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1528])
Data error at batch 3626: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 205.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1528])
Data error at batch 3627: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 205.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1519])
Data error at batch 3628: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 208.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1519])
Data error at batch 3629: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 208.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1462])
Data error at batch 3630: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 232.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1462])
Data error at batch 3631: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.74 GiB is allocated by PyTorch, and 232.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1597])
Data error at batch 3632: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 179.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1597])
Data error at batch 3633: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 179.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1603])
Data error at batch 3634: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 177.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1603])
Data error at batch 3635: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 177.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1616])
Data error at batch 3636: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 171.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1616])
Data error at batch 3637: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 171.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1584])
Data error at batch 3638: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 184.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1584])
Data error at batch 3639: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 184.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 600])
Data error at batch 3640: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 32.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 600])
Data error at batch 3641: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 602])
Data error at batch 3642: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 43.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 602])
Data error at batch 3643: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 43.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 620])
Data error at batch 3644: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 620])
Data error at batch 3645: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 45.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 598])
Data error at batch 3646: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 598])
Data error at batch 3647: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 49.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 682])
Data error at batch 3648: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 682])
Data error at batch 3649: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 674])
Data error at batch 3650: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 674])
Data error at batch 3651: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 51.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 687])
Data error at batch 3652: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 48.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 687])
Data error at batch 3653: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 48.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 659])
Data error at batch 3654: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 43.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 659])
Data error at batch 3655: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 43.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1007])
Data error at batch 3656: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 160.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1007])
Data error at batch 3657: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 160.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1021])
Data error at batch 3658: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1021])
Data error at batch 3659: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1048])
Data error at batch 3660: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 159.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1048])
Data error at batch 3661: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 159.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 989])
Data error at batch 3662: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 175.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 989])
Data error at batch 3663: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 175.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1604])
Data error at batch 3664: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 174.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1604])
Data error at batch 3665: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 174.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1602])
Data error at batch 3666: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 175.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1602])
Data error at batch 3667: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 175.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1636])
Data error at batch 3668: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 161.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1636])
Data error at batch 3669: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 161.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1595])
Data error at batch 3670: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 178.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1595])
Data error at batch 3671: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 178.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1143])
Data error at batch 3672: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 128.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1143])
Data error at batch 3673: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 21.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 128.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1152])
Data error at batch 3674: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 140.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1152])
Data error at batch 3675: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 116.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1175])
Data error at batch 3676: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 110.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1175])
Data error at batch 3677: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 110.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1176])
Data error at batch 3678: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 128.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1176])
Data error at batch 3679: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 102.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1874])
Data error at batch 3680: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1874])
Data error at batch 3681: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1873])
Data error at batch 3682: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1873])
Data error at batch 3683: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 63.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1899])
Data error at batch 3684: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1899])
Data error at batch 3685: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1846])
Data error at batch 3686: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1846])
Data error at batch 3687: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 88.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1643])
Data error at batch 3688: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 170.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1643])
Data error at batch 3689: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 170.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1675])
Data error at batch 3690: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 157.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1675])
Data error at batch 3691: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 157.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1666])
Data error at batch 3692: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1666])
Data error at batch 3693: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1640])
Data error at batch 3694: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1640])
Data error at batch 3695: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1027])
Data error at batch 3696: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 147.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1027])
Data error at batch 3697: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 147.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1074])
Data error at batch 3698: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 134.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1074])
Data error at batch 3699: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 134.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1055])
Data error at batch 3700: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 153.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1055])
Data error at batch 3701: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 153.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1017])
Data error at batch 3702: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1017])
Data error at batch 3703: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 152.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1003])
Data error at batch 3704: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 163.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1003])
Data error at batch 3705: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 163.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1034])
Data error at batch 3706: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 144.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1034])
Data error at batch 3707: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 144.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1060])
Data error at batch 3708: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 150.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1060])
Data error at batch 3709: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 150.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1023])
Data error at batch 3710: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1023])
Data error at batch 3711: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 149.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1395])
Data error at batch 3712: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 220.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1395])
Data error at batch 3713: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 220.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1422])
Data error at batch 3714: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 209.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1422])
Data error at batch 3715: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 209.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1447])
Data error at batch 3716: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 221.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1447])
Data error at batch 3717: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 221.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1411])
Data error at batch 3718: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 214.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1411])
Data error at batch 3719: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 214.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1620])
Data error at batch 3720: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 182.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1620])
Data error at batch 3721: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 182.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1643])
Data error at batch 3722: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 170.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1643])
Data error at batch 3723: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 170.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1659])
Data error at batch 3724: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 163.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1659])
Data error at batch 3725: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 163.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1623])
Data error at batch 3726: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 180.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1623])
Data error at batch 3727: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 180.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 894])
Data error at batch 3728: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 894])
Data error at batch 3729: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 895])
Data error at batch 3730: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 895])
Data error at batch 3731: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 937])
Data error at batch 3732: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 937])
Data error at batch 3733: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 67.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 887])
Data error at batch 3734: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 89.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 887])
Data error at batch 3735: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 89.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 932])
Data error at batch 3736: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 69.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 932])
Data error at batch 3737: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 69.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 928])
Data error at batch 3738: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 928])
Data error at batch 3739: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 73.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 976])
Data error at batch 3740: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 181.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 976])
Data error at batch 3741: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 181.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 912])
Data error at batch 3742: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 912])
Data error at batch 3743: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1033])
Data error at batch 3744: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 144.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1033])
Data error at batch 3745: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 144.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1044])
Data error at batch 3746: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 160.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1044])
Data error at batch 3747: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 160.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1092])
Data error at batch 3748: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 128.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1092])
Data error at batch 3749: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 128.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1049])
Data error at batch 3750: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 157.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1049])
Data error at batch 3751: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 157.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1490])
Data error at batch 3752: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 200.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1490])
Data error at batch 3753: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 200.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1502])
Data error at batch 3754: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 195.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1502])
Data error at batch 3755: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 195.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1528])
Data error at batch 3756: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 186.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1528])
Data error at batch 3757: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 186.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1481])
Data error at batch 3758: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 207.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1481])
Data error at batch 3759: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.77 GiB is allocated by PyTorch, and 207.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 609])
Data error at batch 3760: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 609])
Data error at batch 3761: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 47.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 632])
Data error at batch 3762: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.96 GiB is allocated by PyTorch, and 17.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 632])
Data error at batch 3763: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.96 GiB is allocated by PyTorch, and 17.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 649])
Data error at batch 3764: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 649])
Data error at batch 3765: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 621])
Data error at batch 3766: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 621])
Data error at batch 3767: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 736])
Data error at batch 3768: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 736])
Data error at batch 3769: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 730])
Data error at batch 3770: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 730])
Data error at batch 3771: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 730])
Data error at batch 3772: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 730])
Data error at batch 3773: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 54.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 712])
Data error at batch 3774: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 712])
Data error at batch 3775: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 52.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 872])
Data error at batch 3776: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 107.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 872])
Data error at batch 3777: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 107.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 894])
Data error at batch 3778: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 894])
Data error at batch 3779: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 85.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 878])
Data error at batch 3780: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 103.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 878])
Data error at batch 3781: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 103.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 866])
Data error at batch 3782: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 113.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 866])
Data error at batch 3783: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 113.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 957])
Data error at batch 3784: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 957])
Data error at batch 3785: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 77.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 980])
Data error at batch 3786: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 179.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 980])
Data error at batch 3787: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 179.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1006])
Data error at batch 3788: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1006])
Data error at batch 3789: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 161.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 954])
Data error at batch 3790: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 79.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 954])
Data error at batch 3791: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 79.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 878])
Data error at batch 3792: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 103.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 878])
Data error at batch 3793: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 103.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 899])
Data error at batch 3794: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 82.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 899])
Data error at batch 3795: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 82.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 896])
Data error at batch 3796: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 896])
Data error at batch 3797: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 84.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 860])
Data error at batch 3798: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 118.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 860])
Data error at batch 3799: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 118.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1630])
Data error at batch 3800: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 177.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1630])
Data error at batch 3801: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 177.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1638])
Data error at batch 3802: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 174.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1638])
Data error at batch 3803: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 174.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1662])
Data error at batch 3804: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 162.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1662])
Data error at batch 3805: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 162.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1602])
Data error at batch 3806: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 157.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1602])
Data error at batch 3807: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 157.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 694])
Data error at batch 3808: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 38.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 694])
Data error at batch 3809: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 38.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 700])
Data error at batch 3810: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 700])
Data error at batch 3811: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 679])
Data error at batch 3812: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 679])
Data error at batch 3813: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 51.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 657])
Data error at batch 3814: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 657])
Data error at batch 3815: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 64.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1502])
Data error at batch 3816: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 195.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1502])
Data error at batch 3817: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 195.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1520])
Data error at batch 3818: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 189.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1520])
Data error at batch 3819: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 189.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1541])
Data error at batch 3820: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 184.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1541])
Data error at batch 3821: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 184.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1495])
Data error at batch 3822: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 198.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1495])
Data error at batch 3823: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 198.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1212])
Data error at batch 3824: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 102.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1212])
Data error at batch 3825: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 102.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1221])
Data error at batch 3826: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1221])
Data error at batch 3827: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 98.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1228])
Data error at batch 3828: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 92.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1228])
Data error at batch 3829: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 92.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1192])
Data error at batch 3830: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 112.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1192])
Data error at batch 3831: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 112.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1529])
Data error at batch 3832: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 186.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1529])
Data error at batch 3833: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 186.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1557])
Data error at batch 3834: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 177.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1557])
Data error at batch 3835: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 177.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1546])
Data error at batch 3836: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 181.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1546])
Data error at batch 3837: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 181.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1525])
Data error at batch 3838: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1525])
Data error at batch 3839: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 188.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 791])
Data error at batch 3840: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 791])
Data error at batch 3841: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 61.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 770])
Data error at batch 3842: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 82.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 770])
Data error at batch 3843: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 82.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 807])
Data error at batch 3844: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 807])
Data error at batch 3845: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 57.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 774])
Data error at batch 3846: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 774])
Data error at batch 3847: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 78.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1386])
Data error at batch 3848: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 223.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1386])
Data error at batch 3849: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 223.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1387])
Data error at batch 3850: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 222.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1387])
Data error at batch 3851: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 222.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1437])
Data error at batch 3852: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 226.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1437])
Data error at batch 3853: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 226.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1361])
Data error at batch 3854: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 236.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1361])
Data error at batch 3855: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 5.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 236.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1393])
Data error at batch 3856: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 220.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1393])
Data error at batch 3857: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 220.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1378])
Data error at batch 3858: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 228.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1378])
Data error at batch 3859: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 228.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1389])
Data error at batch 3860: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 222.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1389])
Data error at batch 3861: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 222.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1377])
Data error at batch 3862: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 229.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1377])
Data error at batch 3863: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.75 GiB is allocated by PyTorch, and 229.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1094])
Data error at batch 3864: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 173.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1094])
Data error at batch 3865: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 173.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1088])
Data error at batch 3866: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1088])
Data error at batch 3867: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 129.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1122])
Data error at batch 3868: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 155.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1122])
Data error at batch 3869: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 155.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1095])
Data error at batch 3870: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 173.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1095])
Data error at batch 3871: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 7.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 173.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1938])
Data error at batch 3872: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 35.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 151.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1938])
Data error at batch 3873: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 132.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1990])
Data error at batch 3874: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 31.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 132.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1990])
Data error at batch 3875: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 17.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 74.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2008])
Data error at batch 3876: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 72.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2008])
Data error at batch 3877: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 143.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1945])
Data error at batch 3878: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 102.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1945])
Data error at batch 3879: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 13.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 102.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 652])
Data error at batch 3880: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 55.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 652])
Data error at batch 3881: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 53.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 664])
Data error at batch 3882: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 664])
Data error at batch 3883: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 64.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 662])
Data error at batch 3884: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 43.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 662])
Data error at batch 3885: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 43.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 644])
Data error at batch 3886: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 53.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 644])
Data error at batch 3887: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 53.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1952])
Data error at batch 3888: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 86.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1952])
Data error at batch 3889: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 27.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.28 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 86.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2007])
Data error at batch 3890: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2007])
Data error at batch 3891: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1981])
Data error at batch 3892: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1981])
Data error at batch 3893: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1955])
Data error at batch 3894: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 101.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1955])
Data error at batch 3895: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 101.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1942])
Data error at batch 3896: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 105.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1942])
Data error at batch 3897: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 105.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1941])
Data error at batch 3898: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1941])
Data error at batch 3899: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 106.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1988])
Data error at batch 3900: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 77.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1988])
Data error at batch 3901: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 77.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1929])
Data error at batch 3902: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 110.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1929])
Data error at batch 3903: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 110.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1384])
Data error at batch 3904: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 191.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1384])
Data error at batch 3905: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 191.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1405])
Data error at batch 3906: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 183.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1405])
Data error at batch 3907: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 183.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1423])
Data error at batch 3908: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.70 GiB is allocated by PyTorch, and 278.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1423])
Data error at batch 3909: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.70 GiB is allocated by PyTorch, and 278.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1383])
Data error at batch 3910: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 191.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1383])
Data error at batch 3911: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.78 GiB is allocated by PyTorch, and 191.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1077])
Data error at batch 3912: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 130.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1077])
Data error at batch 3913: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 130.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1084])
Data error at batch 3914: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1084])
Data error at batch 3915: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1102])
Data error at batch 3916: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 116.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1102])
Data error at batch 3917: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 116.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1076])
Data error at batch 3918: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 134.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1076])
Data error at batch 3919: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 134.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1096])
Data error at batch 3920: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 121.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1096])
Data error at batch 3921: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 121.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1086])
Data error at batch 3922: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 126.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1086])
Data error at batch 3923: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 126.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1100])
Data error at batch 3924: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 119.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1100])
Data error at batch 3925: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 119.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1084])
Data error at batch 3926: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1084])
Data error at batch 3927: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.85 GiB is allocated by PyTorch, and 127.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 766])
Data error at batch 3928: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 766])
Data error at batch 3929: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 762])
Data error at batch 3930: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 762])
Data error at batch 3931: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 44.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 785])
Data error at batch 3932: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 62.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 785])
Data error at batch 3933: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 62.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 742])
Data error at batch 3934: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 49.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 742])
Data error at batch 3935: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.92 GiB is allocated by PyTorch, and 49.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 683])
Data error at batch 3936: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 77.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 683])
Data error at batch 3937: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 77.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 687])
Data error at batch 3938: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 687])
Data error at batch 3939: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 74.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 674])
Data error at batch 3940: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 42.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 674])
Data error at batch 3941: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 42.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 646])
Data error at batch 3942: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.94 GiB is allocated by PyTorch, and 43.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 646])
Data error at batch 3943: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 93.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 961])
Data error at batch 3944: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 19.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 59.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 961])
Data error at batch 3945: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 81.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 977])
Data error at batch 3946: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 75.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 977])
Data error at batch 3947: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 75.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1011])
Data error at batch 3948: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 54.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1011])
Data error at batch 3949: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 54.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 950])
Data error at batch 3950: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 115.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 950])
Data error at batch 3951: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 115.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1851])
Data error at batch 3952: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.93 GiB is allocated by PyTorch, and 46.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1851])
Data error at batch 3953: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 82.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1836])
Data error at batch 3954: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 88.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1836])
Data error at batch 3955: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 88.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1841])
Data error at batch 3956: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1841])
Data error at batch 3957: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 86.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1828])
Data error at batch 3958: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1828])
Data error at batch 3959: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 91.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1562])
Data error at batch 3960: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1562])
Data error at batch 3961: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1584])
Data error at batch 3962: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 159.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1584])
Data error at batch 3963: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 159.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1607])
Data error at batch 3964: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 183.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1607])
Data error at batch 3965: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 183.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1553])
Data error at batch 3966: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 174.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1553])
Data error at batch 3967: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 9.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.80 GiB is allocated by PyTorch, and 174.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 790])
Data error at batch 3968: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 58.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 790])
Data error at batch 3969: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 58.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 782])
Data error at batch 3970: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 782])
Data error at batch 3971: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 66.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 827])
Data error at batch 3972: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 827])
Data error at batch 3973: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 94.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 780])
Data error at batch 3974: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 68.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 780])
Data error at batch 3975: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 11.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 68.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 3075])
Data error at batch 3976: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 62.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 3075])
Data error at batch 3977: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 62.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 3096])
Data error at batch 3978: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 54.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 3096])
Data error at batch 3979: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 54.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 3135])
Data error at batch 3980: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 47.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 3135])
Data error at batch 3981: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.89 GiB is allocated by PyTorch, and 47.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 3087])
Data error at batch 3982: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 59.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 3087])
Data error at batch 3983: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 43.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.27 GiB memory in use. Of the allocated memory 5.88 GiB is allocated by PyTorch, and 59.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1991])
Data error at batch 3984: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 15.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.29 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 153.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1991])
Data error at batch 3985: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 165.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1973])
Data error at batch 3986: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1973])
Data error at batch 3987: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 171.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2031])
Data error at batch 3988: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 153.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 2031])
Data error at batch 3989: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.83 GiB is allocated by PyTorch, and 153.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1980])
Data error at batch 3990: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 169.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1980])
Data error at batch 3991: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.81 GiB is allocated by PyTorch, and 169.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1171])
Data error at batch 3992: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1171])
Data error at batch 3993: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 1.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.31 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 80.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1186])
Data error at batch 3994: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1186])
Data error at batch 3995: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 71.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1178])
Data error at batch 3996: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1178])
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [02:02<00:00, 122.84s/it]100%|██████████| 1/1 [02:02<00:00, 122.84s/it]
Data error at batch 3997: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.90 GiB is allocated by PyTorch, and 75.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1163])
Data error at batch 3998: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 111.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([1, 1163])
Data error at batch 3999: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 79.32 GiB of which 3.56 MiB is free. Process 221980 has 72.01 GiB memory in use. Including non-PyTorch memory, this process has 7.30 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 111.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error finetuning cnn/cnn_500_ft_llama_detection_finetuning_data_version_1: Cannot copy out of meta tensor; no data!
Saving for reuse
Traceback (most recent call last):
  File "/mnt/petrelfs/majiachen/self_recognition/llama_finetune.py", line 119, in finetune
    model.save_pretrained(f"finetuned_models/{file}.pt") 
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/petrelfs/majiachen/self_recognition/venv/lib/python3.11/site-packages/peft/peft_model.py", line 364, in save_pretrained
    safe_save_file(
  File "/mnt/petrelfs/majiachen/self_recognition/venv/lib/python3.11/site-packages/safetensors/torch.py", line 281, in save_file
    serialize_file(_flatten(tensors), filename, metadata=metadata)
                   ^^^^^^^^^^^^^^^^^
  File "/mnt/petrelfs/majiachen/self_recognition/venv/lib/python3.11/site-packages/safetensors/torch.py", line 485, in _flatten
    return {
           ^
  File "/mnt/petrelfs/majiachen/self_recognition/venv/lib/python3.11/site-packages/safetensors/torch.py", line 489, in <dictcomp>
    "data": _tobytes(v, k),
            ^^^^^^^^^^^^^^
  File "/mnt/petrelfs/majiachen/self_recognition/venv/lib/python3.11/site-packages/safetensors/torch.py", line 411, in _tobytes
    tensor = tensor.to("cpu")
             ^^^^^^^^^^^^^^^^
NotImplementedError: Cannot copy out of meta tensor; no data!

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/petrelfs/majiachen/self_recognition/llama_finetune.py", line 136, in <module>
    finetune(args.file)
  File "/mnt/petrelfs/majiachen/self_recognition/llama_finetune.py", line 124, in finetune
    model.save_pretrained(f"finetuned_models/{file}.pt") 
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/petrelfs/majiachen/self_recognition/venv/lib/python3.11/site-packages/peft/peft_model.py", line 364, in save_pretrained
    safe_save_file(
  File "/mnt/petrelfs/majiachen/self_recognition/venv/lib/python3.11/site-packages/safetensors/torch.py", line 281, in save_file
    serialize_file(_flatten(tensors), filename, metadata=metadata)
                   ^^^^^^^^^^^^^^^^^
  File "/mnt/petrelfs/majiachen/self_recognition/venv/lib/python3.11/site-packages/safetensors/torch.py", line 485, in _flatten
    return {
           ^
  File "/mnt/petrelfs/majiachen/self_recognition/venv/lib/python3.11/site-packages/safetensors/torch.py", line 489, in <dictcomp>
    "data": _tobytes(v, k),
            ^^^^^^^^^^^^^^
  File "/mnt/petrelfs/majiachen/self_recognition/venv/lib/python3.11/site-packages/safetensors/torch.py", line 411, in _tobytes
    tensor = tensor.to("cpu")
             ^^^^^^^^^^^^^^^^
NotImplementedError: Cannot copy out of meta tensor; no data!
srun: error: SH-IDC1-10-140-1-129: task 0: Exited with exit code 1
